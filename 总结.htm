<!DOCTYPE html>
<html><head>
		<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
		<title>Zotero 报告</title>
		<link rel="stylesheet" type="text/css" href="data:text/css;base64,Ym9keSB7CgliYWNrZ3JvdW5kOiB3aGl0ZTsKfQoKYSB7Cgl0ZXh0LWRlY29yYXRpb246IHVuZGVybGluZTsKfQoKYm9keSB7CglwYWRkaW5nOiAwOwp9Cgp1bC5yZXBvcnQgbGkuaXRlbSB7Cglib3JkZXItdG9wOiA0cHggc29saWQgIzU1NTsKCXBhZGRpbmctdG9wOiAxZW07CglwYWRkaW5nLWxlZnQ6IDFlbTsKCXBhZGRpbmctcmlnaHQ6IDFlbTsKCW1hcmdpbi1ib3R0b206IDJlbTsKfQoKaDEsIGgyLCBoMywgaDQsIGg1LCBoNiB7Cglmb250LXdlaWdodDogbm9ybWFsOwp9CgpoMiB7CgltYXJnaW46IDAgMCAuNWVtOwp9CgpoMi5wYXJlbnRJdGVtIHsKCWZvbnQtd2VpZ2h0OiBib2xkOwoJZm9udC1zaXplOiAxZW07CglwYWRkaW5nOiAwIDAgLjVlbTsKCWJvcmRlci1ib3R0b206IDFweCBzb2xpZCAjY2NjOwp9CgovKiBJZiBjb21iaW5pbmcgY2hpbGRyZW4sIGRpc3BsYXkgcGFyZW50IHNsaWdodGx5IGxhcmdlciAqLwp1bC5yZXBvcnQuY29tYmluZUNoaWxkSXRlbXMgaDIucGFyZW50SXRlbSB7Cglmb250LXNpemU6IDEuMWVtOwoJcGFkZGluZy1ib3R0b206IC43NWVtOwoJbWFyZ2luLWJvdHRvbTogLjRlbTsKfQoKaDIucGFyZW50SXRlbSAudGl0bGUgewoJZm9udC13ZWlnaHQ6IG5vcm1hbDsKfQoKaDMgewoJbWFyZ2luLWJvdHRvbTogLjZlbTsKCWZvbnQtd2VpZ2h0OiBib2xkICFpbXBvcnRhbnQ7Cglmb250LXNpemU6IDFlbTsKCWRpc3BsYXk6IGJsb2NrOwp9CgovKiBNZXRhZGF0YSB0YWJsZSAqLwp0aCB7Cgl2ZXJ0aWNhbC1hbGlnbjogdG9wOwoJdGV4dC1hbGlnbjogcmlnaHQ7Cgl3aWR0aDogMTUlOwoJd2hpdGUtc3BhY2U6IG5vd3JhcDsKfQoKdGQgewoJcGFkZGluZy1sZWZ0OiAuNWVtOwp9CgoKdWwucmVwb3J0LCB1bC5ub3RlcywgdWwudGFncyB7CglsaXN0LXN0eWxlOiBub25lOwoJbWFyZ2luLWxlZnQ6IDA7CglwYWRkaW5nLWxlZnQ6IDA7Cn0KCi8qIFRhZ3MgKi8KaDMudGFncyB7Cglmb250LXNpemU6IDEuMWVtOwp9Cgp1bC50YWdzIHsKCWxpbmUtaGVpZ2h0OiAxLjc1ZW07CglsaXN0LXN0eWxlOiBub25lOwp9Cgp1bC50YWdzIGxpIHsKCWRpc3BsYXk6IGlubGluZTsKfQoKdWwudGFncyBsaTpub3QoOmxhc3QtY2hpbGQpOmFmdGVyIHsKCWNvbnRlbnQ6ICcsICc7Cn0KCgovKiBDaGlsZCBub3RlcyAqLwpoMy5ub3RlcyB7Cglmb250LXNpemU6IDEuMWVtOwp9Cgp1bC5ub3RlcyB7CgltYXJnaW4tYm90dG9tOiAxLjJlbTsKfQoKdWwubm90ZXMgPiBsaTpmaXJzdC1jaGlsZCBwIHsKCW1hcmdpbi10b3A6IDA7Cn0KCnVsLm5vdGVzID4gbGkgewoJcGFkZGluZzogLjdlbSAwOwp9Cgp1bC5ub3RlcyA+IGxpOm5vdCg6bGFzdC1jaGlsZCkgewoJYm9yZGVyLWJvdHRvbTogMXB4ICNjY2Mgc29saWQ7Cn0KCgp1bC5ub3RlcyA+IGxpIHA6Zmlyc3QtY2hpbGQgewoJbWFyZ2luLXRvcDogMDsKfQoKdWwubm90ZXMgPiBsaSBwOmxhc3QtY2hpbGQgewoJbWFyZ2luLWJvdHRvbTogMDsKfQoKLyogQWRkIHF1b3RhdGlvbiBtYXJrcyBhcm91bmQgYmxvY2txdW90ZSAqLwp1bC5ub3RlcyA+IGxpIGJsb2NrcXVvdGUgcDpub3QoOmVtcHR5KTpiZWZvcmUsCmxpLm5vdGUgYmxvY2txdW90ZSBwOm5vdCg6ZW1wdHkpOmJlZm9yZSB7Cgljb250ZW50OiAn4oCcJzsKfQoKdWwubm90ZXMgPiBsaSBibG9ja3F1b3RlIHA6bm90KDplbXB0eSk6bGFzdC1jaGlsZDphZnRlciwKbGkubm90ZSBibG9ja3F1b3RlIHA6bm90KDplbXB0eSk6bGFzdC1jaGlsZDphZnRlciB7Cgljb250ZW50OiAn4oCdJzsKfQoKLyogUHJlc2VydmUgd2hpdGVzcGFjZSBvbiBwbGFpbnRleHQgbm90ZXMgKi8KdWwubm90ZXMgbGkgcC5wbGFpbnRleHQsIGxpLm5vdGUgcC5wbGFpbnRleHQsIGRpdi5ub3RlIHAucGxhaW50ZXh0IHsKCXdoaXRlLXNwYWNlOiBwcmUtd3JhcDsKfQoKLyogRGlzcGxheSB0YWdzIHdpdGhpbiBjaGlsZCBub3RlcyBpbmxpbmUgKi8KdWwubm90ZXMgaDMudGFncyB7CglkaXNwbGF5OiBpbmxpbmU7Cglmb250LXNpemU6IDFlbTsKfQoKdWwubm90ZXMgaDMudGFnczphZnRlciB7Cgljb250ZW50OiAnICc7Cn0KCnVsLm5vdGVzIHVsLnRhZ3MgewoJZGlzcGxheTogaW5saW5lOwp9Cgp1bC5ub3RlcyB1bC50YWdzIGxpOm5vdCg6bGFzdC1jaGlsZCk6YWZ0ZXIgewoJY29udGVudDogJywgJzsKfQoKCi8qIENoaWxkIGF0dGFjaG1lbnRzICovCmgzLmF0dGFjaG1lbnRzIHsKCWZvbnQtc2l6ZTogMS4xZW07Cn0KCnVsLmF0dGFjaG1lbnRzIGxpIHsKCXBhZGRpbmctdG9wOiAuNWVtOwp9Cgp1bC5hdHRhY2htZW50cyBkaXYubm90ZSB7CgltYXJnaW4tbGVmdDogMmVtOwp9Cgp1bC5hdHRhY2htZW50cyBkaXYubm90ZSBwOmZpcnN0LWNoaWxkIHsKCW1hcmdpbi10b3A6IC43NWVtOwp9CgpkaXYgdGFibGUgewoJYm9yZGVyLWNvbGxhcHNlOiBjb2xsYXBzZTsKfQoKZGl2IHRhYmxlIHRkLCBkaXYgdGFibGUgdGggewoJYm9yZGVyOiAxcHggI2NjYyBzb2xpZDsKCWJvcmRlci1jb2xsYXBzZTogY29sbGFwc2U7Cgl3b3JkLWJyZWFrOiBicmVhay1hbGw7Cn0KCmRpdiB0YWJsZSB0ZCBwOmVtcHR5OjphZnRlciwgZGl2IHRhYmxlIHRoIHA6ZW1wdHk6OmFmdGVyIHsKCWNvbnRlbnQ6ICJcMDBhMCI7Cn0KCmRpdiB0YWJsZSB0ZCAqOmZpcnN0LWNoaWxkLCBkaXYgdGFibGUgdGggKjpmaXJzdC1jaGlsZCB7CgltYXJnaW4tdG9wOiAwOwp9CgpkaXYgdGFibGUgdGQgKjpsYXN0LWNoaWxkLCBkaXYgdGFibGUgdGggKjpsYXN0LWNoaWxkIHsKCW1hcmdpbi1ib3R0b206IDA7Cn0K">
		<link rel="stylesheet" type="text/css" media="screen,projection" href="data:text/css;base64,LyogR2VuZXJpYyBzdHlsZXMgKi8KYm9keSB7Cglmb250OiA2Mi41JSBHZW9yZ2lhLCBUaW1lcywgc2VyaWY7Cgl3aWR0aDogNzgwcHg7CgltYXJnaW46IDAgYXV0bzsKfQoKaDIgewoJZm9udC1zaXplOiAxLjVlbTsKCWxpbmUtaGVpZ2h0OiAxLjVlbTsKCWZvbnQtZmFtaWx5OiBHZW9yZ2lhLCBUaW1lcywgc2VyaWY7Cn0KCnAgewoJbGluZS1oZWlnaHQ6IDEuNWVtOwp9CgphOmxpbmssIGE6dmlzaXRlZCB7Cgljb2xvcjogIzkwMDsKfQoKYTpob3ZlciwgYTphY3RpdmUgewoJY29sb3I6ICM3Nzc7Cn0KCgp1bC5yZXBvcnQgewoJZm9udC1zaXplOiAxLjRlbTsKCXdpZHRoOiA2ODBweDsKCW1hcmdpbjogMCBhdXRvOwoJcGFkZGluZzogMjBweCAyMHB4Owp9CgovKiBNZXRhZGF0YSB0YWJsZSAqLwp0YWJsZSB7Cglib3JkZXI6IDFweCAjY2NjIHNvbGlkOwoJb3ZlcmZsb3c6IGF1dG87Cgl3aWR0aDogMTAwJTsKCW1hcmdpbjogLjFlbSBhdXRvIC43NWVtOwoJcGFkZGluZzogMC41ZW07Cn0K">
		<link rel="stylesheet" type="text/css" media="print" href="data:text/css;base64,Ym9keSB7Cglmb250OiAxMnB0ICJUaW1lcyBOZXcgUm9tYW4iLCBUaW1lcywgR2VvcmdpYSwgc2VyaWY7CgltYXJnaW46IDA7Cgl3aWR0aDogYXV0bzsKCWNvbG9yOiBibGFjazsKfQoKLyogUGFnZSBCcmVha3MgKHBhZ2UtYnJlYWstaW5zaWRlIG9ubHkgcmVjb2duaXplZCBieSBPcGVyYSkgKi8KaDEsIGgyLCBoMywgaDQsIGg1LCBoNiB7CglwYWdlLWJyZWFrLWFmdGVyOiBhdm9pZDsKCXBhZ2UtYnJlYWstaW5zaWRlOiBhdm9pZDsKfQoKdWwsIG9sLCBkbCB7CglwYWdlLWJyZWFrLWluc2lkZTogYXZvaWQ7Cgljb2xvci1hZGp1c3Q6IGV4YWN0Owp9CgpoMiB7Cglmb250LXNpemU6IDEuM2VtOwoJbGluZS1oZWlnaHQ6IDEuM2VtOwp9CgphIHsKCWNvbG9yOiAjMDAwOwoJdGV4dC1kZWNvcmF0aW9uOiBub25lOwp9Cg==">
	</head>
	<body>
		<ul class="report combineChildItems">
			<li id="item_PXH7DTU2" class="item conferencePaper">
			<h2>A black-box attack model for visually-aware recommender systems</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>会议论文</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Rami Cohen</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Oren Sar Shalom</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Dietmar Jannach</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Amihood Amir</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2021</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Google Scholar</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>94–102</td>
					</tr>
					<tr>
					<th>会议论文集标题</th>
						<td>Proceedings of the 14th ACM International Conference on Web Search and Data Mining</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午7:26:43</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/17 下午6:42:28</td>
					</tr>
				</tbody></table>
				<h3 class="tags">标签：</h3>
				<ul class="tags">
					<li>Black-box</li>
					<li>Visual</li>
				</ul>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_9N8MFNUN">Full Text					</li>
					<li id="item_3GAY87Z2">Snapshot					</li>
				</ul>
			</li>


			<li id="item_QIN26HJ4" class="item conferencePaper">
			<h2>A CNN-based Hybrid Model and Architecture for Shilling Attack Detection</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>会议论文</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Mahsa Ebrahimian</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Rasha Kashef</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2021</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Google Scholar</td>
					</tr>
					<tr>
					<th>出版社</th>
						<td>IEEE</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>1–7</td>
					</tr>
					<tr>
					<th>会议论文集标题</th>
						<td>2021 IEEE Canadian Conference on Electrical and Computer Engineering (CCECE)</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午8:16:59</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午8:32:40</td>
					</tr>
				</tbody></table>
				<h3 class="tags">标签：</h3>
				<ul class="tags">
					<li>Computational modeling</li>
					<li>Conferences</li>
					<li>Data models</li>
					<li>Benchmark testing</li>
					<li>Compatibility</li>
					<li>Computer architecture</li>
					<li>Deep learning</li>
					<li>Divergence Criterion</li>
					<li>Neural Networks</li>
					<li>Predictive models</li>
					<li>Recommendation systems</li>
					<li>Shilling attacks</li>
				</ul>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_A8LY6RSW">IEEE Xplore Abstract Record					</li>
					<li id="item_N8S5UB9X">IEEE Xplore Full Text PDF					</li>
					<li id="item_V2LK4G5H">Snapshot					</li>
				</ul>
			</li>


			<li id="item_QRSYYAIU" class="item journalArticle">
			<h2>A genre trust model for defending shilling attacks in recommender systems</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>期刊文章</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Li Yang</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Xinxin Niu</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2021</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Google Scholar</td>
					</tr>
					<tr>
					<th>其它</th>
						<td>Publisher: Springer</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>1–14</td>
					</tr>
					<tr>
					<th>期刊</th>
						<td>Complex &amp; Intelligent Systems</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午7:56:31</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午8:32:41</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_HHESVIIK">Full Text					</li>
					<li id="item_YVDES9VM">Yang 和 Niu - 2021 - A genre trust model for defending shilling attacks.pdf					</li>
				</ul>
			</li>


			<li id="item_B3IQ3I5I" class="item conferencePaper">
			<h2>A Regression Framework to Interpret the Robustness of Recommender Systems Against Shilling Attacks.</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>会议论文</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Yashar Deldjoo</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Tommaso Di Noia</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Eugenio Di Sciascio</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Felice Antonio Merra</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2021</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Google Scholar</td>
					</tr>
					<tr>
					<th>会议论文集标题</th>
						<td>IIR</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午7:56:31</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午7:56:31</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_FBIPWRZE">Full Text					</li>
				</ul>
			</li>


			<li id="item_GHRXEGJK" class="item journalArticle">
			<h2>A survey of attack detection approaches in collaborative filtering recommender systems</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>期刊文章</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Fatemeh Rezaimehr</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Chitra Dadkhah</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2021</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Google Scholar</td>
					</tr>
					<tr>
					<th>其它</th>
						<td>Publisher: Springer</td>
					</tr>
					<tr>
					<th>卷次</th>
						<td>54</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>2011–2066</td>
					</tr>
					<tr>
					<th>期刊</th>
						<td>Artificial Intelligence Review</td>
					</tr>
					<tr>
					<th>期号</th>
						<td>3</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午7:28:34</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午7:28:34</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_D7T7389B">Snapshot					</li>
				</ul>
			</li>


			<li id="item_A5JM45BW" class="item journalArticle">
			<h2>A survey on adversarial attack in the age of artificial intelligence</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>期刊文章</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Zixiao Kong</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Jingfeng Xue</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Yong Wang</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Lu Huang</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Zequn Niu</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Feng Li</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2021</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Google Scholar</td>
					</tr>
					<tr>
					<th>其它</th>
						<td>Publisher: Hindawi</td>
					</tr>
					<tr>
					<th>卷次</th>
						<td>2021</td>
					</tr>
					<tr>
					<th>期刊</th>
						<td>Wireless Communications and Mobile Computing</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午7:23:52</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午7:23:52</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_7XEPPL87">Full Text					</li>
				</ul>
			</li>


			<li id="item_Q4DJ8GEL" class="item journalArticle">
			<h2>A Survey on Adversarial Recommender Systems: From Attack/Defense Strategies to Generative Adversarial Networks</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>期刊文章</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Yashar Deldjoo</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Tommaso Di Noia</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Felice Antonio Merra</td>
					</tr>
					<tr>
					<th>摘要</th>
						<td>Latent-factor models (LFM) based on collaborative filtering 
(CF), such as matrix factorization (MF) and deep CF methods, are widely 
used in modern recommender systems (RS) due to their excellent 
performance and recommendation accuracy. However, success has been 
accompanied with a major new arising challenge:
              Many applications of machine learning (ML) are adversarial
 in nature
              [146]. In recent years, it has been shown that these 
methods are vulnerable to adversarial examples, i.e., subtle but 
non-random perturbations designed to force recommendation models to 
produce erroneous outputs.
            
            The goal of this survey is two-fold: (i) to present recent 
advances on adversarial machine learning (AML) for the security of RS 
(i.e., attacking and defense recommendation models) and (ii) to show 
another successful application of AML in generative adversarial networks
 (GANs) for generative applications, thanks to their ability for 
learning (high-dimensional) data distributions. In this survey, we 
provide an exhaustive literature review of 76 articles published in 
major RS and ML journals and conferences. This review serves as a 
reference for the RS community working on the security of RS or on 
generative models using GANs to improve their quality.</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2022-03-31</td>
					</tr>
					<tr>
					<th>语言</th>
						<td>en</td>
					</tr>
					<tr>
					<th>短标题</th>
						<td>A Survey on Adversarial Recommender Systems</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://dl.acm.org/doi/10.1145/3439729">https://dl.acm.org/doi/10.1145/3439729</a></td>
					</tr>
					<tr>
					<th>访问时间</th>
						<td>2022/11/15 上午2:35:53</td>
					</tr>
					<tr>
					<th>卷次</th>
						<td>54</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>1-38</td>
					</tr>
					<tr>
					<th>期刊</th>
						<td>ACM Computing Surveys</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1145/3439729">10.1145/3439729</a></td>
					</tr>
					<tr>
					<th>期号</th>
						<td>2</td>
					</tr>
					<tr>
					<th>刊名缩写</th>
						<td>ACM Comput. Surv.</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>0360-0300, 1557-7341</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/15 上午2:35:53</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午8:32:45</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_5EHZBJS9">Deldjoo 等 - 2022 - A Survey on Adversarial Recommender Systems From .pdf					</li>
				</ul>
			</li>


			<li id="item_IXMUXL6T" class="item webpage">
			<h2>A Survey on Adversarial Recommender Systems: From Attack/Defense 
Strategies to Generative Adversarial Networks: ACM Computing Surveys: 
Vol 54, No 2</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>网页</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://dl.acm.org/doi/abs/10.1145/3439729">https://dl.acm.org/doi/abs/10.1145/3439729</a></td>
					</tr>
					<tr>
					<th>访问时间</th>
						<td>2022/11/16 下午6:44:08</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午6:44:08</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午6:44:08</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_MATNJ64E">全文					</li>
				</ul>
			</li>


			<li id="item_SH95YP6U" class="item journalArticle">
			<h2>Adversarial Attacks and Defenses in Deep Learning: from a Perspective of Cybersecurity</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>期刊文章</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Shuai Zhou</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Chi Liu</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Dayong Ye</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Tianqing Zhu</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Wanlei Zhou</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Philip S. Yu</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2021</td>
					</tr>
					<tr>
					<th>短标题</th>
						<td>Adversarial Attacks and Defenses in Deep Learning</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Google Scholar</td>
					</tr>
					<tr>
					<th>其它</th>
						<td>Publisher: ACM New York, NY</td>
					</tr>
					<tr>
					<th>期刊</th>
						<td>ACM Computing Surveys (CSUR)</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午6:49:21</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午8:32:48</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_5ZJ6AN99">Snapshot					</li>
					<li id="item_TBVKRGU8">Zhou 等 - 2022 - Adversarial Attacks and Defenses in Deep Learning.pdf					</li>
				</ul>
			</li>


			<li id="item_GZC3IXT2" class="item conferencePaper">
			<h2>Adversarial Attacks to API Recommender Systems: Time to Wake Up and Smell the Coffee?</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>会议论文</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Phuong T. Nguyen</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Claudio Di Sipio</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Juri Di Rocco</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Massimiliano Di Penta</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Davide Di Ruscio</td>
					</tr>
					<tr>
					<th>摘要</th>
						<td>Recommender systems in software engineering provide developers
 with a wide range of valuable items to help them complete their tasks. 
Among others, API recommender systems have gained momentum in recent 
years as they became more successful at suggesting API calls or code 
snippets. While these systems have proven to be effective in terms of 
prediction accuracy, there has been less attention for what concerns 
such recommenders’ resilience against adversarial attempts. In fact, by 
crafting the recommenders’ learning material, e.g., data from large 
open-source software (OSS) repositories, hostile users may succeed in 
injecting malicious data, putting at risk the software clients adopting 
API recommender systems. In this paper, we present an empirical 
investigation of adversarial machine learning techniques and their 
possible influence on recommender systems. The evaluation performed on 
three state-of-the-art API recommender systems reveals a worrying 
outcome: all of them are not immune to malicious data. The obtained 
result triggers the need for effective countermeasures to protect 
recommender systems against hostile attacks disguised in training data.</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2021-11</td>
					</tr>
					<tr>
					<th>短标题</th>
						<td>Adversarial Attacks to API Recommender Systems</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>IEEE Xplore</td>
					</tr>
					<tr>
					<th>其它</th>
						<td>ISSN: 2643-1572</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>253-265</td>
					</tr>
					<tr>
					<th>会议论文集标题</th>
						<td>2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE)</td>
					</tr>
					<tr>
					<th>会议名称</th>
						<td>2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE)</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/ASE51524.2021.9678946">10.1109/ASE51524.2021.9678946</a></td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午8:30:15</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午8:30:15</td>
					</tr>
				</tbody></table>
				<h3 class="tags">标签：</h3>
				<ul class="tags">
					<li>Recommender systems</li>
					<li>Task analysis</li>
					<li>Adversarial Attacks</li>
					<li>Adversarial machine learning</li>
					<li>Adversarial Machine Learning</li>
					<li>API Mining</li>
					<li>Codes</li>
					<li>Open source software</li>
					<li>Software engineering</li>
					<li>Training data</li>
				</ul>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_6CYTH4DR">IEEE Xplore Full Text PDF					</li>
				</ul>
			</li>


			<li id="item_VHFETS3M" class="item conferencePaper">
			<h2>Adversarial Attacks to API Recommender Systems: Time to Wake Up and Smell the Coffeeƒ</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>会议论文</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Phuong T. Nguyen</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Claudio Di Sipio</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Juri Di Rocco</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Massimiliano Di Penta</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Davide Di Ruscio</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2021</td>
					</tr>
					<tr>
					<th>短标题</th>
						<td>Adversarial Attacks to API Recommender Systems</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Google Scholar</td>
					</tr>
					<tr>
					<th>出版社</th>
						<td>IEEE</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>253–265</td>
					</tr>
					<tr>
					<th>会议论文集标题</th>
						<td>2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE)</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午6:48:03</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午6:48:03</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_3EQNKNPJ">Snapshot					</li>
				</ul>
			</li>


			<li id="item_BEIM5Z6P" class="item preprint">
			<h2>Adversarial Recommendation: Attack of the Learned Fake Users</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>预印本</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Konstantina Christakopoulou</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Arindam Banerjee</td>
					</tr>
					<tr>
					<th>摘要</th>
						<td>Can machine learning models for recommendation be easily 
fooled? While the question has been answered for hand-engineered fake 
user profiles, it has not been explored for machine learned adversarial 
attacks. This paper attempts to close this gap. We propose a framework 
for generating fake user profiles which, when incorporated in the 
training of a recommendation system, can achieve an adversarial intent, 
while remaining indistinguishable from real user profiles. We formulate 
this procedure as a repeated general-sum game between two players: an 
oblivious recommendation system $R$ and an adversarial fake user 
generator $A$ with two goals: (G1) the rating distribution of the fake 
users needs to be close to the real users, and (G2) some objective $f_A$
 encoding the attack intent, such as targeting the top-K recommendation 
quality of $R$ for a subset of users, needs to be optimized. We propose a
 learning framework to achieve both goals, and offer extensive 
experiments considering multiple types of attacks highlighting the 
vulnerability of recommendation systems.</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2018-09-21</td>
					</tr>
					<tr>
					<th>短标题</th>
						<td>Adversarial Recommendation</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>arXiv.org</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://arxiv.org/abs/1809.08336">http://arxiv.org/abs/1809.08336</a></td>
					</tr>
					<tr>
					<th>访问时间</th>
						<td>2022/11/17 上午12:25:26</td>
					</tr>
					<tr>
					<th>其它</th>
						<td>arXiv:1809.08336 [cs, stat]</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.48550/arXiv.1809.08336">10.48550/arXiv.1809.08336</a></td>
					</tr>
					<tr>
					<th>仓库</th>
						<td>arXiv</td>
					</tr>
					<tr>
					<th>存档ID</th>
						<td>arXiv:1809.08336</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/17 上午12:25:26</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/17 上午12:25:26</td>
					</tr>
				</tbody></table>
				<h3 class="tags">标签：</h3>
				<ul class="tags">
					<li>Computer Science - Information Retrieval</li>
					<li>Computer Science - Machine Learning</li>
					<li>Statistics - Machine Learning</li>
				</ul>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_89KGR27A">arXiv Fulltext PDF					</li>
					<li id="item_ZFS9SPJ7">arXiv.org Snapshot					</li>
				</ul>
			</li>


			<li id="item_WY6JZXKM" class="item bookSection">
			<h2>Adversarial recommender systems: Attack, defense, and advances</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>图书章节</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Vito Walter Anelli</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Yashar Deldjoo</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Tommaso DiNoia</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Felice Antonio Merra</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2022</td>
					</tr>
					<tr>
					<th>短标题</th>
						<td>Adversarial recommender systems</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Google Scholar</td>
					</tr>
					<tr>
					<th>出版社</th>
						<td>Springer</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>335–379</td>
					</tr>
					<tr>
					<th>书名</th>
						<td>Recommender systems handbook</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午6:47:11</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午6:47:11</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_ZUS4DW4T">Snapshot					</li>
				</ul>
			</li>


			<li id="item_ULBCKVL2" class="item journalArticle">
			<h2>An adaptive RNN algorithm to detect shilling attacks for online products in hybrid recommender system</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>期刊文章</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Akanksha Bansal Chopra</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Veer Sain Dixit</td>
					</tr>
					<tr>
					<th>摘要</th>
						<td>Recommender system (RS) depends on the thoughts of numerous 
users to predict the favourites of potential consumers. RS is vulnerable
 to malicious information. Unsuitable products can be oﬀered to the user
 by injecting a few unscrupulous “shilling” proﬁles like push and nuke 
attacks into the RS. Injection of these attacks results in the wrong 
recommendation for a product. The aim of this research is to develop a 
framework that can be widely utilized to make excellent recommendations 
for sales growth. This study uses the methodology that presents an 
enhanced clustering algorithm named as modiﬁed density peak clustering 
algorithm on the consumer review dataset to ensure a well-formed 
cluster. An improved recurrent neural network algorithm is proposed to 
detect these attacks in hybrid RS, which uses the content-based RS and 
collaborative ﬁltering RS. The results are compared with other state of 
the art algorithms. The proposed method is more suitable for E-commerce 
applications where the number of customers and products grows rapidly.</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2022-10-31</td>
					</tr>
					<tr>
					<th>语言</th>
						<td>en</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://www.degruyter.com/document/doi/10.1515/jisys-2022-1023/html">https://www.degruyter.com/document/doi/10.1515/jisys-2022-1023/html</a></td>
					</tr>
					<tr>
					<th>访问时间</th>
						<td>2022/11/16 下午8:16:34</td>
					</tr>
					<tr>
					<th>卷次</th>
						<td>31</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>1133-1149</td>
					</tr>
					<tr>
					<th>期刊</th>
						<td>Journal of Intelligent Systems</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1515/jisys-2022-1023">10.1515/jisys-2022-1023</a></td>
					</tr>
					<tr>
					<th>期号</th>
						<td>1</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>2191-026X</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午8:16:35</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午8:16:35</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_DQ8LQ9K4">Chopra 和 Dixit - 2022 - An adaptive RNN algorithm to detect shilling attac.pdf					</li>
				</ul>
			</li>


			<li id="item_L7ZAE65X" class="item webpage">
			<h2>An adaptive RNN algorithm to detect shilling attacks for online products in hybrid recommender system</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>网页</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://www.degruyter.com/document/doi/10.1515/jisys-2022-1023/html">https://www.degruyter.com/document/doi/10.1515/jisys-2022-1023/html</a></td>
					</tr>
					<tr>
					<th>访问时间</th>
						<td>2022/11/16 下午8:15:24</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午8:15:24</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午8:15:24</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_ZSMJ6LEI">全文					</li>
					<li id="item_NKS98U5M">An adaptive RNN algorithm to detect shilling attacks for online products in hybrid recommender system					</li>
				</ul>
			</li>


			<li id="item_3JBUUVT4" class="item journalArticle">
			<h2>An Empirical Analysis of Collaborative Recommender Systems Robustness to Shilling Attacks</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>期刊文章</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Anu Shrestha</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Francesca Spezzano</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Maria Soledad Pera</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2021</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Google Scholar</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午6:49:21</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午8:32:52</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_DC4VEVD2">Full Text					</li>
					<li id="item_LGRLMT9L">Snapshot					</li>
				</ul>
			</li>


			<li id="item_IWIK5UI8" class="item journalArticle">
			<h2>An Unsupervised Approach for Detecting Group Shilling Attacks in 
Recommender Systems Based on Topological Potential and Group Behaviour 
Features</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>期刊文章</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Hongyun Cai</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Fuzhi Zhang</td>
					</tr>
					<tr>
						<th class="editor">编辑</th>
						<td>Rutvij Jhaveri</td>
					</tr>
					<tr>
					<th>摘要</th>
						<td>To protect recommender systems against shilling attacks, a 
variety of detection methods have been proposed over the past decade. 
However, these methods focus mainly on individual features and rarely 
consider the lockstep behaviours among attack users, which suffer from 
low precision in detecting group shilling attacks. In this work, we 
propose a three-stage detection method based on strong lockstep 
behaviours among group members and group behaviour features for 
detecting group shilling attacks. First, we construct a weighted user 
relationship graph by combining direct and indirect collusive degrees 
between users. Second, we find all dense subgraphs in the user 
relationship graph to generate a set of suspicious groups by introducing
 a topological potential method. Finally, we use a clustering method to 
detect shilling groups by extracting group behaviour features. Extensive
 experiments on the Netflix and sampled Amazon review datasets show that
 the proposed approach is effective for detecting group shilling attacks
 in recommender systems, and the F1-measure on two datasets can reach 
over 99 percent and 76 percent, respectively.</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2021-9-27</td>
					</tr>
					<tr>
					<th>语言</th>
						<td>en</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://www.hindawi.com/journals/scn/2021/2907691/">https://www.hindawi.com/journals/scn/2021/2907691/</a></td>
					</tr>
					<tr>
					<th>访问时间</th>
						<td>2022/11/16 下午8:02:52</td>
					</tr>
					<tr>
					<th>卷次</th>
						<td>2021</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>1-18</td>
					</tr>
					<tr>
					<th>期刊</th>
						<td>Security and Communication Networks</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1155/2021/2907691">10.1155/2021/2907691</a></td>
					</tr>
					<tr>
					<th>刊名缩写</th>
						<td>Security and Communication Networks</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>1939-0122, 1939-0114</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午8:02:52</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午8:02:52</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_B244YRDK">Cai 和 Zhang - 2021 - An Unsupervised Approach for Detecting Group Shill.pdf					</li>
				</ul>
			</li>


			<li id="item_Y7FTIDBD" class="item conferencePaper">
			<h2>Attacking black-box recommendations via copying cross-domain user profiles</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>会议论文</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Wenqi Fan</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Tyler Derr</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Xiangyu Zhao</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Yao Ma</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Hui Liu</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Jianping Wang</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Jiliang Tang</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Qing Li</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2021</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Google Scholar</td>
					</tr>
					<tr>
					<th>出版社</th>
						<td>IEEE</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>1583–1594</td>
					</tr>
					<tr>
					<th>会议论文集标题</th>
						<td>2021 IEEE 37th International Conference on Data Engineering (ICDE)</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午6:45:50</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午6:45:50</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_C99L9J8P">Full Text					</li>
					<li id="item_EZQAS8QU">Snapshot					</li>
				</ul>
			</li>


			<li id="item_GD2JUSDS" class="item journalArticle">
			<h2>Attacking recommender systems with plausible profile</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>期刊文章</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Xuxin Zhang</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Jian Chen</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Rui Zhang</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Chen Wang</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Ling Liu</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2021</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Google Scholar</td>
					</tr>
					<tr>
					<th>其它</th>
						<td>Publisher: IEEE</td>
					</tr>
					<tr>
					<th>卷次</th>
						<td>16</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>4788–4800</td>
					</tr>
					<tr>
					<th>期刊</th>
						<td>IEEE Transactions on Information Forensics and Security</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午6:48:03</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午8:32:53</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_H362K8VC">Full Text					</li>
					<li id="item_4XEA7S7A">Snapshot					</li>
				</ul>
			</li>


			<li id="item_4I78DFKE" class="item conferencePaper">
			<h2>Black-Box Attacks on Sequential Recommenders via Data-Free Model Extraction</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>会议论文</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Zhenrui Yue</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Zhankui He</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Huimin Zeng</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Julian McAuley</td>
					</tr>
					<tr>
					<th>摘要</th>
						<td>We investigate whether model extraction can be used to ‘steal’
 the weights of sequential recommender systems, and the potential 
threats posed to victims of such attacks. This type of risk has 
attracted attention in image and text classification, but to our 
knowledge not in recommender systems. We argue that sequential 
recommender systems are subject to unique vulnerabilities due to the 
specific autoregressive regimes used to train them. Unlike many existing
 recommender attackers, which assume the dataset used to train the 
victim model is exposed to attackers, we consider a data-free setting, 
where training data are not accessible. Under this setting, we propose 
an API-based model extraction method via limited-budget synthetic data 
generation and knowledge distillation. We investigate state-of-the-art 
models for sequential recommendation and show their vulnerability under 
model extraction and downstream attacks. We perform attacks in two 
stages. (1) Model extraction: given different types of synthetic data 
and their labels retrieved from a black-box recommender, we extract the 
black-box model to a white-box model via distillation. (2) Downstream 
attacks: we attack the black-box model with adversarial samples 
generated by the white-box recommender. Experiments show the 
effectiveness of our data-free model extraction and downstream attacks 
on sequential recommenders in both profile pollution and data poisoning 
settings.</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2021-09-13</td>
					</tr>
					<tr>
					<th>语言</th>
						<td>en</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://dl.acm.org/doi/10.1145/3460231.3474275">https://dl.acm.org/doi/10.1145/3460231.3474275</a></td>
					</tr>
					<tr>
					<th>访问时间</th>
						<td>2022/11/17 上午12:33:38</td>
					</tr>
					<tr>
					<th>地点</th>
						<td>Amsterdam Netherlands</td>
					</tr>
					<tr>
					<th>出版社</th>
						<td>ACM</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-1-4503-8458-2</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>44-54</td>
					</tr>
					<tr>
					<th>会议论文集标题</th>
						<td>Fifteenth ACM Conference on Recommender Systems</td>
					</tr>
					<tr>
					<th>会议名称</th>
						<td>RecSys '21: Fifteenth ACM Conference on Recommender Systems</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1145/3460231.3474275">10.1145/3460231.3474275</a></td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/17 上午12:33:38</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/17 上午12:33:38</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_QWGBTCSR">Yue 等 - 2021 - Black-Box Attacks on Sequential Recommenders via D.pdf					</li>
				</ul>
			</li>


			<li id="item_6C9T8QD2" class="item webpage">
			<h2>Black-Box Attacks on Sequential Recommenders via Data-Free Model 
Extraction | Proceedings of the 15th ACM Conference on Recommender 
Systems</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>网页</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://dl.acm.org/doi/abs/10.1145/3460231.3474275">https://dl.acm.org/doi/abs/10.1145/3460231.3474275</a></td>
					</tr>
					<tr>
					<th>访问时间</th>
						<td>2022/11/17 上午12:30:37</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/17 上午12:30:37</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/17 上午12:30:37</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_P3LWIANE">全文					</li>
					<li id="item_MBY4CFUV">Black-Box Attacks on Sequential Recommenders
 via Data-Free Model Extraction | Proceedings of the 15th ACM Conference
 on Recommender Systems					</li>
				</ul>
			</li>


			<li id="item_7GM9QFJ2" class="item journalArticle">
			<h2>Comprehensive Privacy Analysis on Federated Recommender System against Attribute Inference Attacks</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>期刊文章</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Shijie Zhang</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Hongzhi Yin</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2022</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Google Scholar</td>
					</tr>
					<tr>
					<th>期刊</th>
						<td>arXiv preprint arXiv:2205.11857</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午7:58:52</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午7:58:52</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_9NXH6EC7">Full Text					</li>
					<li id="item_35IGXHTT">Snapshot					</li>
				</ul>
			</li>


			<li id="item_ZEQG2G8C" class="item conferencePaper">
			<h2>Data Poisoning Attack against Recommender System Using Incomplete and Perturbed Data</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>会议论文</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Hengtong Zhang</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Changxin Tian</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Yaliang Li</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Lu Su</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Nan Yang</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Wayne Xin Zhao</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Jing Gao</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2021</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Google Scholar</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>2154–2164</td>
					</tr>
					<tr>
					<th>会议论文集标题</th>
						<td>Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午7:28:34</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午7:28:34</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_WQGZUIU6">Full Text					</li>
					<li id="item_HMHCSP9S">Snapshot					</li>
				</ul>
			</li>


			<li id="item_R9ZJVVTE" class="item journalArticle">
			<h2>Data poisoning attacks on neighborhood-based recommender systems</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>期刊文章</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Liang Chen</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Yangjun Xu</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Fenfang Xie</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Min Huang</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Zibin Zheng</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2021</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Google Scholar</td>
					</tr>
					<tr>
					<th>其它</th>
						<td>Publisher: Wiley Online Library</td>
					</tr>
					<tr>
					<th>卷次</th>
						<td>32</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>e3872</td>
					</tr>
					<tr>
					<th>期刊</th>
						<td>Transactions on Emerging Telecommunications Technologies</td>
					</tr>
					<tr>
					<th>期号</th>
						<td>6</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午6:45:50</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午6:45:50</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_IEHL7JPE">Full Text					</li>
					<li id="item_M2HMLJCL">Snapshot					</li>
				</ul>
			</li>


			<li id="item_W5BDZDME" class="item conferencePaper">
			<h2>Data Poisoning Attacks on Stochastic Bandits</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>会议论文</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Fang Liu</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Ness Shroff</td>
					</tr>
					<tr>
					<th>摘要</th>
						<td>Stochastic multi-armed bandits form a class of online learning
 problems that have important applications in online recommendation 
systems, adaptive medical treatment, and many others. Even though 
potential attacks against these learning algorithms may hijack their 
behavior, causing catastrophic loss in real-world applications, little 
is known about adversarial attacks on bandit algorithms. In this paper, 
we propose a framework of offline attacks on bandit algorithms and study
 convex optimization based attacks on several popular bandit algorithms.
 We show that the attacker can force the bandit algorithm to pull a 
target arm with high probability by a slight manipulation of the rewards
 in the data. Then we study a form of online attacks on bandit 
algorithms and propose an adaptive attack strategy against any bandit 
algorithm without the knowledge of the bandit algorithm. Our adaptive 
attack strategy can hijack the behavior of the bandit algorithm to 
suffer a linear regret with only a logarithmic cost to the attacker. Our
 results demonstrate a significant security threat to stochastic 
bandits.</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2019-05-24</td>
					</tr>
					<tr>
					<th>语言</th>
						<td>en</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>proceedings.mlr.press</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://proceedings.mlr.press/v97/liu19e.html">https://proceedings.mlr.press/v97/liu19e.html</a></td>
					</tr>
					<tr>
					<th>访问时间</th>
						<td>2022/11/17 上午12:37:04</td>
					</tr>
					<tr>
					<th>其它</th>
						<td>ISSN: 2640-3498</td>
					</tr>
					<tr>
					<th>出版社</th>
						<td>PMLR</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>4042-4050</td>
					</tr>
					<tr>
					<th>会议论文集标题</th>
						<td>Proceedings of the 36th International Conference on Machine Learning</td>
					</tr>
					<tr>
					<th>会议名称</th>
						<td>International Conference on Machine Learning</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/17 上午12:37:04</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/17 上午12:37:04</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_EY4RIUAU">Full Text PDF					</li>
					<li id="item_TJL9LS7G">Supplementary PDF					</li>
				</ul>
			</li>


			<li id="item_6A2FZHIT" class="item webpage">
			<h2>Data Poisoning Attacks on Stochastic Bandits</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>网页</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://proceedings.mlr.press/v97/liu19e.html">http://proceedings.mlr.press/v97/liu19e.html</a></td>
					</tr>
					<tr>
					<th>访问时间</th>
						<td>2022/11/17 上午12:36:52</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/17 上午12:36:52</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/17 上午12:36:52</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_KB6AM6V9">全文					</li>
					<li id="item_HLUBW4A5">Data Poisoning Attacks on Stochastic Bandits					</li>
				</ul>
			</li>


			<li id="item_RM6SUY4W" class="item journalArticle">
			<h2>Data poisoning attacks to deep learning based recommender systems</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>期刊文章</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Hai Huang</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Jiaming Mu</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Neil Zhenqiang Gong</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Qi Li</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Bin Liu</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Mingwei Xu</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2021</td>
					</tr>
					<tr>
					<th>短标题</th>
						<td>⬚⬚中毒攻击数据深度学习为基础的推荐系统</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Google Scholar</td>
					</tr>
					<tr>
					<th>期刊</th>
						<td>arXiv preprint arXiv:2101.02644</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午6:45:50</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/17 上午12:37:33</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_RYAE4LPC">Full Text					</li>
					<li id="item_R9PSKJ4M">Snapshot					</li>
				</ul>
			</li>


			<li id="item_VWCQHI5W" class="item conferencePaper">
			<h2>Debiasing Learning for Membership Inference Attacks Against Recommender Systems</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>会议论文</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Zihan Wang</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Na Huang</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Fei Sun</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Pengjie Ren</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Zhumin Chen</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Hengliang Luo</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Maarten de Rijke</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Zhaochun Ren</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2022</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Google Scholar</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>1959–1968</td>
					</tr>
					<tr>
					<th>会议论文集标题</th>
						<td>Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午7:34:14</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午7:34:14</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_36X72FMZ">Full Text					</li>
					<li id="item_BAELIE5B">Snapshot					</li>
				</ul>
			</li>


			<li id="item_LVMZZECD" class="item journalArticle">
			<h2>Deep Model Poisoning Attack on Federated Learning</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>期刊文章</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Xingchen Zhou</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Ming Xu</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Yiming Wu</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Ning Zheng</td>
					</tr>
					<tr>
					<th>摘要</th>
						<td>Federated learning is a novel distributed learning framework, 
which enables thousands of participants to collaboratively construct a 
deep learning model. In order to protect conﬁdentiality of the training 
data, the shared information between server and participants are only 
limited to model parameters. However, this setting is vulnerable to 
model poisoning attack, since the participants have permission to modify
 the model parameters. In this paper, we perform systematic 
investigation for such threats in federated learning and propose a novel
 optimization-based model poisoning attack. Different from existing 
methods, we primarily focus on the effectiveness, persistence and 
stealth of attacks. Numerical experiments demonstrate that the proposed 
method can not only achieve high attack success rate, but it is also 
stealthy enough to bypass two existing defense methods.</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2021-03-14</td>
					</tr>
					<tr>
					<th>语言</th>
						<td>en</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://www.mdpi.com/1999-5903/13/3/73">https://www.mdpi.com/1999-5903/13/3/73</a></td>
					</tr>
					<tr>
					<th>访问时间</th>
						<td>2022/11/17 下午6:00:53</td>
					</tr>
					<tr>
					<th>卷次</th>
						<td>13</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>73</td>
					</tr>
					<tr>
					<th>期刊</th>
						<td>Future Internet</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.3390/fi13030073">10.3390/fi13030073</a></td>
					</tr>
					<tr>
					<th>期号</th>
						<td>3</td>
					</tr>
					<tr>
					<th>刊名缩写</th>
						<td>Future Internet</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>1999-5903</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/17 下午6:00:53</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/17 下午6:00:53</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_XSNTVEW4">Zhou 等 - 2021 - Deep Model Poisoning Attack on Federated Learning.pdf					</li>
				</ul>
			</li>


			<li id="item_TJ77PTYW" class="item journalArticle">
			<h2>Defending a Music Recommender Against Hubness-Based Adversarial Attacks</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>期刊文章</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Katharina Hoedt</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Arthur Flexer</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Gerhard Widmer</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2022</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Google Scholar</td>
					</tr>
					<tr>
					<th>期刊</th>
						<td>arXiv preprint arXiv:2205.12032</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午7:58:52</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午7:58:52</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_UV7MGFMH">Full Text					</li>
					<li id="item_MVB86YQK">Snapshot					</li>
				</ul>
			</li>


			<li id="item_G4LE8P75" class="item conferencePaper">
			<h2>Defending Substitution-Based Profile Pollution Attacks on Sequential Recommenders</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>会议论文</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Zhenrui Yue</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Huimin Zeng</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Ziyi Kou</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Lanyu Shang</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Dong Wang</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2022</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Google Scholar</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>59–70</td>
					</tr>
					<tr>
					<th>会议论文集标题</th>
						<td>Proceedings of the 16th ACM Conference on Recommender Systems</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午8:18:26</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午8:18:26</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_ZR42W8A5">Full Text					</li>
					<li id="item_VB9DTJUZ">Snapshot					</li>
				</ul>
			</li>


			<li id="item_2ELRB2FF" class="item journalArticle">
			<h2>Detecting Group Shilling Attacks In Online Recommender Systems</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>期刊文章</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>B. Sharmila</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>D. Narmada</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Krishna Keerthana</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>K. L. Mounika</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2021</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Google Scholar</td>
					</tr>
					<tr>
					<th>卷次</th>
						<td>12</td>
					</tr>
					<tr>
					<th>期刊</th>
						<td>journal of engineering science</td>
					</tr>
					<tr>
					<th>期号</th>
						<td>05</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午7:54:32</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午7:54:32</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_4AKW2HKB">Full Text					</li>
				</ul>
			</li>


			<li id="item_N5LFB5K6" class="item conferencePaper">
			<h2>Detecting group shilling attacks in recommender systems based on maximum dense subtensor mining</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>会议论文</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Hongtao Yu</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Haihong Zheng</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Yishu Xu</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Ru Ma</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Dingli Gao</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Fuzhi Zhang</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2021</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Google Scholar</td>
					</tr>
					<tr>
					<th>出版社</th>
						<td>IEEE</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>644–648</td>
					</tr>
					<tr>
					<th>会议论文集标题</th>
						<td>2021 IEEE International Conference on Artificial Intelligence and Computer Applications (ICAICA)</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午7:56:31</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/17 下午5:33:25</td>
					</tr>
				</tbody></table>
				<h3 class="tags">标签：</h3>
				<ul class="tags">
					<li>Conferences</li>
					<li>Data models</li>
					<li>dual-input convolutional neural network</li>
					<li>Feature extraction</li>
					<li>Fuses</li>
					<li>group shilling attacks</li>
					<li>Knowledge engineering</li>
					<li>maximum dense subtensor mining</li>
					<li>recommender systems</li>
					<li>Tensors</li>
					<li>Time series analysis</li>
				</ul>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_TL3TW6PI">IEEE Xplore Full Text PDF					</li>
					<li id="item_W2YT6YUY">Snapshot					</li>
				</ul>
			</li>


			<li id="item_6CER2LNE" class="item journalArticle">
			<h2>Detecting shilling groups in online recommender systems based on graph convolutional network</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>期刊文章</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Shilei Wang</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Peng Zhang</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Hui Wang</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Hongtao Yu</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Fuzhi Zhang</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2022</td>
					</tr>
					<tr>
					<th>短标题</th>
						<td>⬚⬚在线检测先令团体推荐系统基于图像卷积网络</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Google Scholar</td>
					</tr>
					<tr>
					<th>其它</th>
						<td>Publisher: Elsevier</td>
					</tr>
					<tr>
					<th>卷次</th>
						<td>59</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>103031</td>
					</tr>
					<tr>
					<th>期刊</th>
						<td>Information Processing &amp; Management</td>
					</tr>
					<tr>
					<th>期号</th>
						<td>5</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午8:11:12</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/17 下午5:40:12</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_ISJMEH29">Snapshot					</li>
					<li id="item_DEYLRIGG">Wang 等 - 2022 - Detecting shilling groups in online recommender sy.pdf					</li>
				</ul>
			</li>


			<li id="item_TJX25VTN" class="item conferencePaper">
			<h2>Detecting shilling groups in recommender systems based on hierarchical topic model</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>会议论文</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Shilei Wang</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Hui Wang</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Hongtao Yu</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Fuzhi Zhang</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2021</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Google Scholar</td>
					</tr>
					<tr>
					<th>出版社</th>
						<td>IEEE</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>832–837</td>
					</tr>
					<tr>
					<th>会议论文集标题</th>
						<td>2021 IEEE International Conference on Artificial Intelligence and Computer Applications (ICAICA)</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午7:58:52</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/17 下午5:40:13</td>
					</tr>
				</tbody></table>
				<h3 class="tags">标签：</h3>
				<ul class="tags">
					<li>Artificial intelligence</li>
					<li>Clustering</li>
					<li>Clustering algorithms</li>
					<li>Computational modeling</li>
					<li>Computer applications</li>
					<li>Conferences</li>
					<li>Group shilling attacks</li>
					<li>Hierarchical topic model</li>
					<li>Natural language processing</li>
					<li>Optics</li>
					<li>Recommender systems</li>
					<li>Shilling group detection</li>
				</ul>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_7QTURNRP">IEEE Xplore Abstract Record					</li>
					<li id="item_4IQ9HG6L">IEEE Xplore Full Text PDF					</li>
					<li id="item_DULGLWJV">Snapshot					</li>
				</ul>
			</li>


			<li id="item_746D2JKI" class="item journalArticle">
			<h2>Detection of shilling attack in recommender system for YouTube video statistics using machine learning techniques</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>期刊文章</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Shalli Rani</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Manpreet Kaur</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Munish Kumar</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Vinayakumar Ravi</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Uttam Ghosh</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Jnyana Ranjan Mohanty</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2021</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Google Scholar</td>
					</tr>
					<tr>
					<th>其它</th>
						<td>Publisher: Springer</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>1–13</td>
					</tr>
					<tr>
					<th>期刊</th>
						<td>Soft Computing</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午6:48:03</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午6:48:03</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_IDSDDG26">Snapshot					</li>
				</ul>
			</li>


			<li id="item_B47GJAIY" class="item journalArticle">
			<h2>Detection of Trust Shilling Attacks in Recommender Systems</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>期刊文章</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Xian CHEN</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Xi DENG</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Chensen HUANG</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Hyoseop SHIN</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2022</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Google Scholar</td>
					</tr>
					<tr>
					<th>其它</th>
						<td>Publisher: The Institute of Electronics, Information and Communication Engineers</td>
					</tr>
					<tr>
					<th>卷次</th>
						<td>105</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>1239–1242</td>
					</tr>
					<tr>
					<th>期刊</th>
						<td>IEICE TRANSACTIONS on Information and Systems</td>
					</tr>
					<tr>
					<th>期号</th>
						<td>6</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午7:54:32</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午7:54:32</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_PBC5K7ZL">Full Text					</li>
					<li id="item_WN7WARVI">Snapshot					</li>
				</ul>
			</li>


			<li id="item_LMTYTT4T" class="item journalArticle">
			<h2>FedAttack: Effective and Covert Poisoning Attack on Federated Recommendation via Hard Sampling</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>期刊文章</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Chuhan Wu</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Fangzhao Wu</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Tao Qi</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Yongfeng Huang</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Xing Xie</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2022</td>
					</tr>
					<tr>
					<th>短标题</th>
						<td>FedAttack</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Google Scholar</td>
					</tr>
					<tr>
					<th>期刊</th>
						<td>arXiv preprint arXiv:2202.04975</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午7:54:32</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午7:54:32</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_W4PKPWSX">Full Text					</li>
					<li id="item_7Y67IR5Z">Snapshot					</li>
				</ul>
			</li>


			<li id="item_V6IQ98P8" class="item preprint">
			<h2>FedRecAttack: Model Poisoning Attack to Federated Recommendation</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>预印本</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Dazhong Rong</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Shuai Ye</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Ruoyan Zhao</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Hon Ning Yuen</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Jianhai Chen</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Qinming He</td>
					</tr>
					<tr>
					<th>摘要</th>
						<td>Federated Recommendation (FR) has received considerable 
popularity and attention in the past few years. In FR, for each user, 
its feature vector and interaction data are kept locally on its own 
client thus are private to others. Without the access to above 
information, most existing poisoning attacks against recommender systems
 or federated learning lose validity. Beniﬁting from this 
characteristic, FR is commonly considered fairly secured. However, we 
argue that there is still possible and necessary security improvement 
could be made in FR. To prove our opinion, in this paper we present 
FedRecAttack, a model poisoning attack to FR aiming to raise the 
exposure ratio of target items. In most recommendation scenarios, apart 
from private user-item interactions (e.g., clicks, watches and 
purchases), some interactions are public (e.g., likes, follows and 
comments). Motivated by this point, in FedRecAttack we make use of the 
public interactions to approximate users’ feature vectors, thereby 
attacker can generate poisoned gradients accordingly and control 
malicious users to upload the poisoned gradients in a well-designed way.
 To evaluate the effectiveness and side effects of FedRecAttack, we 
conduct extensive experiments on three real-world datasets of different 
sizes from two completely different scenarios. Experimental results 
demonstrate that our proposed FedRecAttack achieves the state-of-the-art
 effectiveness while its side effects are negligible. Moreover, even 
with small proportion (3%) of malicious users and small proportion (1%) 
of public interactions, FedRecAttack remains highly effective, which 
reveals that FR is more vulnerable to attack than people commonly 
considered.</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2022-10-13</td>
					</tr>
					<tr>
					<th>语言</th>
						<td>en</td>
					</tr>
					<tr>
					<th>短标题</th>
						<td>FedRecAttack</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>arXiv.org</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://arxiv.org/abs/2204.01499">http://arxiv.org/abs/2204.01499</a></td>
					</tr>
					<tr>
					<th>访问时间</th>
						<td>2022/11/15 上午2:35:49</td>
					</tr>
					<tr>
					<th>其它</th>
						<td>arXiv:2204.01499 [cs]</td>
					</tr>
					<tr>
					<th>仓库</th>
						<td>arXiv</td>
					</tr>
					<tr>
					<th>存档ID</th>
						<td>arXiv:2204.01499</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/15 上午2:35:49</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午8:33:17</td>
					</tr>
				</tbody></table>
				<h3 class="tags">标签：</h3>
				<ul class="tags">
					<li>Computer Science - Cryptography and Security</li>
					<li>Computer Science - Machine Learning</li>
				</ul>
				<h3 class="notes">笔记：</h3>
				<ul class="notes">
					<li id="item_FTH72QXT">
<p class="plaintext">Comment: This paper has been accepted by IEEE International Conference on Data Engineering 2022 (Second Research Round)</p>
					</li>
					<li id="item_9LNY2XB4">
<p class="plaintext">Comment: This paper has been accepted by IEEE International Conference on Data Engineering 2022 (Second Research Round)</p>
					</li>
				</ul>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_9LY27IUY">arXiv.org Snapshot					</li>
					<li id="item_RGEASMAF">Rong 等 - 2022 - FedRecAttack Model Poisoning Attack to Federated .pdf					</li>
				</ul>
			</li>


			<li id="item_TPXF3EHL" class="item conferencePaper">
			<h2>Fight Fire with Fire: Towards Robust Recommender Systems via Adversarial Poisoning Training</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>会议论文</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Chenwang Wu</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Defu Lian</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Yong Ge</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Zhihao Zhu</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Enhong Chen</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Senchao Yuan</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2021</td>
					</tr>
					<tr>
					<th>短标题</th>
						<td>Fight Fire with Fire</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Google Scholar</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>1074–1083</td>
					</tr>
					<tr>
					<th>会议论文集标题</th>
						<td>Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午7:54:32</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午7:54:32</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_MWID8SPD">Full Text					</li>
					<li id="item_FQ7LK9M4">Snapshot					</li>
				</ul>
			</li>


			<li id="item_MLNU3VWN" class="item journalArticle">
			<h2>Fusing hypergraph spectral features for shilling attack detection</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>期刊文章</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Hao Li</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Min Gao</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Fengtao Zhou</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Yueyang Wang</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Qilin Fan</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Linda Yang</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2021</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Google Scholar</td>
					</tr>
					<tr>
					<th>其它</th>
						<td>Publisher: Elsevier</td>
					</tr>
					<tr>
					<th>卷次</th>
						<td>63</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>103051</td>
					</tr>
					<tr>
					<th>期刊</th>
						<td>Journal of Information Security and Applications</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午6:48:35</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/17 下午6:31:25</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_J549B3NY">Li 等 - 2021 - Fusing hypergraph spectral features for shilling a.pdf					</li>
					<li id="item_9AMZUEW9">Li 等 - 2021 - Fusing hypergraph spectral features for shilling a.pdf					</li>
					<li id="item_BJTVTNPF">Snapshot					</li>
				</ul>
			</li>


			<li id="item_468GFVAI" class="item journalArticle">
			<h2>Gray-Box Shilling Attack: An Adversarial Learning Approach</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>期刊文章</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Zongwei Wang</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Min Gao</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Jundong Li</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Junwei Zhang</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Jiang Zhong</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2022</td>
					</tr>
					<tr>
					<th>短标题</th>
						<td>Gray-Box Shilling Attack</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Google Scholar</td>
					</tr>
					<tr>
					<th>其它</th>
						<td>Publisher: ACM New York, NY</td>
					</tr>
					<tr>
					<th>期刊</th>
						<td>ACM Transactions on Intelligent Systems and Technology (TIST)</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午7:34:14</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午7:34:14</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_YYPNB5FR">Full Text					</li>
					<li id="item_FDD6FGBH">Snapshot					</li>
				</ul>
			</li>


			<li id="item_PQTMBC3N" class="item journalArticle">
			<h2>Hybrid convolutional neural network (CNN) and long-short term 
memory (LSTM) based deep learning model for detecting shilling attack in
 the social-aware network</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>期刊文章</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Kalimuthu Vivekanandan</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Narayanan Praveena</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2021</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Google Scholar</td>
					</tr>
					<tr>
					<th>其它</th>
						<td>Publisher: Springer</td>
					</tr>
					<tr>
					<th>卷次</th>
						<td>12</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>1197–1210</td>
					</tr>
					<tr>
					<th>期刊</th>
						<td>Journal of Ambient Intelligence and Humanized Computing</td>
					</tr>
					<tr>
					<th>期号</th>
						<td>1</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午8:11:12</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午8:11:12</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_X3J82JJL">Snapshot					</li>
				</ul>
			</li>


			<li id="item_TGMMJDUW" class="item conferencePaper">
			<h2>IEEE13-AdvAttack A Novel Dataset for Benchmarking the Power of 
Adversarial Attacks against Fault Prediction Systems in Smart Electrical
 Grid</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>会议论文</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Carmelo Ardito</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Yashar Deldjoo</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Tommaso Di Noia</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Eugenio Di Sciascio</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Fatemeh Nazary</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2022</td>
					</tr>
					<tr>
					<th>短标题</th>
						<td>⬚⬚IEEE13-AdvAttack小说为基准数据集的力量对抗攻击智能电网故障预测系统</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Google Scholar</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>3817–3821</td>
					</tr>
					<tr>
					<th>会议论文集标题</th>
						<td>Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午6:49:21</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/17 上午12:23:36</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_N59NC49V">Full Text					</li>
					<li id="item_GDDM26LX">Snapshot					</li>
				</ul>
			</li>


			<li id="item_ZMIRDI9R" class="item journalArticle">
			<h2>IMPACT ANALYSIS OF PROFILE INJECTION ATTACKS IN RECOMMENDER SYSTEM</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>期刊文章</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>M. Ashish Kumar</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Yudhvir Singh</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Vikas Siwach</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Harkesh Sehrawat</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2021</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Google Scholar</td>
					</tr>
					<tr>
					<th>卷次</th>
						<td>9</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>472–478</td>
					</tr>
					<tr>
					<th>期刊</th>
						<td>INFORMATION TECHNOLOGY IN INDUSTRY</td>
					</tr>
					<tr>
					<th>期号</th>
						<td>1</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午7:58:52</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午7:58:52</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_6FK7IXAM">Full Text					</li>
					<li id="item_2DUFYM37">Snapshot					</li>
				</ul>
			</li>


			<li id="item_Y2LC3QV8" class="item journalArticle">
			<h2>Improving Deep Learning-Based Recommendation Attack Detection Using Harris Hawks Optimization</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>期刊文章</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Quanqiang Zhou</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Cheng Huang</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Liangliang Duan</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2022</td>
					</tr>
					<tr>
					<th>短标题</th>
						<td>⬚⬚改善深上优于推荐攻击检测使用哈里斯鹰优化</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Google Scholar</td>
					</tr>
					<tr>
					<th>其它</th>
						<td>Publisher: MDPI</td>
					</tr>
					<tr>
					<th>卷次</th>
						<td>12</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>10135</td>
					</tr>
					<tr>
					<th>期刊</th>
						<td>Applied Sciences</td>
					</tr>
					<tr>
					<th>期号</th>
						<td>19</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午8:11:12</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/17 下午6:31:27</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_ZEVKXLES">Snapshot					</li>
					<li id="item_4U8ZAF4Z">Zhou 等 - 2022 - Improving Deep Learning-Based Recommendation Attac.pdf					</li>
				</ul>
			</li>


			<li id="item_MGUB3YG5" class="item conferencePaper">
			<h2>Influence Function based Data Poisoning Attacks to Top-N Recommender Systems</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>会议论文</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Minghong Fang</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Neil Zhenqiang Gong</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Jia Liu</td>
					</tr>
					<tr>
					<th>摘要</th>
						<td>Recommender system is an essential component of web services 
to engage users. Popular recommender systems model user preferences and 
item properties using a large amount of crowdsourced user-item 
interaction data, e.g., rating scores; then top-N items that match the 
best with a user’s preference are recommended to the user. In this work,
 we show that an attacker can launch a data poisoning attack to a 
recommender system to make recommendations as the attacker desires via 
injecting fake users with carefully crafted user-item interaction data. 
Specifically, an attacker can trick a recommender system to recommend a 
target item to as many normal users as possible. We focus on matrix 
factorization based recommender systems because they have been widely 
deployed in industry. Given the number of fake users the attacker can 
inject, we formulate the crafting of rating scores for the fake users as
 an optimization problem. However, this optimization problem is 
challenging to solve as it is a non-convex integer programming problem. 
To address the challenge, we develop several techniques to approximately
 solve the optimization problem. For instance, we leverage influence 
function to select a subset of normal users who are influential to the 
recommendations and solve our formulated optimization problem based on 
these influential users. Our results show that our attacks are effective
 and outperform existing methods.</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>四月 20, 2020</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>ACM Digital Library</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://doi.org/10.1145/3366423.3380072">https://doi.org/10.1145/3366423.3380072</a></td>
					</tr>
					<tr>
					<th>访问时间</th>
						<td>2022/11/16 上午8:00:00</td>
					</tr>
					<tr>
					<th>地点</th>
						<td>New York, NY, USA</td>
					</tr>
					<tr>
					<th>出版社</th>
						<td>Association for Computing Machinery</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-1-4503-7023-3</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>3019–3025</td>
					</tr>
					<tr>
					<th>系列</th>
						<td>WWW '20</td>
					</tr>
					<tr>
					<th>会议论文集标题</th>
						<td>Proceedings of The Web Conference 2020</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1145/3366423.3380072">10.1145/3366423.3380072</a></td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/17 上午12:34:56</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/17 上午12:35:00</td>
					</tr>
				</tbody></table>
				<h3 class="tags">标签：</h3>
				<ul class="tags">
					<li>adversarial machine learning.</li>
					<li>Adversarial recommender systems</li>
					<li>data poisoning attacks</li>
				</ul>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_389J7YZ6">全文					</li>
				</ul>
			</li>


			<li id="item_JBLWPTFL" class="item conferencePaper">
			<h2>Injection Shilling Attack Tool for Recommender Systems</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>会议论文</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Fatemeh Rezaimehr</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Chitra Dadkhah</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2021</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Google Scholar</td>
					</tr>
					<tr>
					<th>出版社</th>
						<td>IEEE</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>1–4</td>
					</tr>
					<tr>
					<th>会议论文集标题</th>
						<td>2021 26th International Computer Conference, Computer Society of Iran (CSICC)</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午7:34:14</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午7:34:14</td>
					</tr>
				</tbody></table>
			</li>


			<li id="item_K879GHUB" class="item journalArticle">
			<h2>Item-triggered recommendation for identifying potential customers of cold sellers in supermarkets</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>期刊文章</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>San Diego</td>
					</tr>
					<tr>
					<th>语言</th>
						<td>en</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Zotero</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>105</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/17 上午12:27:59</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/17 上午12:28:34</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_JIZJHKBW">Diego - Beyond Personalization 2005.pdf					</li>
				</ul>
			</li>


			<li id="item_ERVQMW7W" class="item journalArticle">
			<h2>Link farm, an effective attack to Page Rank in algorithm in graph-based recommender systems</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>期刊文章</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Sima Iranmanesh</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Mohammad-Reza Pajoohan</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2021</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Google Scholar</td>
					</tr>
					<tr>
					<th>其它</th>
						<td>Publisher: Babol Noshirvani University of Technology</td>
					</tr>
					<tr>
					<th>卷次</th>
						<td>10</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>53–67</td>
					</tr>
					<tr>
					<th>期刊</th>
						<td>Journal of Soft Computing and Information Technology</td>
					</tr>
					<tr>
					<th>期号</th>
						<td>2</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午7:34:14</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午7:34:14</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_36BLEPUG">Snapshot					</li>
				</ul>
			</li>


			<li id="item_D4CNRAPL" class="item journalArticle">
			<h2>LOKI: A Practical Data Poisoning Attack Framework against Next Item Recommendations</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>期刊文章</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Hengtong Zhang</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Yaliang Li</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Bolin Ding</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Jing Gao</td>
					</tr>
					<tr>
					<th>摘要</th>
						<td>Due to the openness of the online platform, recommendation 
systems are vulnerable to data poisoning attacks, where malicious 
samples are injected into the training set of the recommendation system 
to manipulate its recommendation results. Existing attack approaches are
 either based on heuristic rules or designed against specific 
recommendation approaches. The former suffers unsatisfactory 
performance, while the latter requires strong knowledge of the target 
system. In this paper, we propose a practical poisoning attack approach 
named LOKI against blackbox recommendation systems. The proposed LOKI 
utilizes the reinforcement learning algorithm to train the attack agent,
 which can be used to generate user behavior samples for data poisoning.
 In real-world recommendation systems, the cost of retraining 
recommendation models is high, and the interaction frequency between 
users and a recommendation system is restricted. Thus, we propose to let
 the agent interact with a recommender simulator instead of the target 
recommendation system and leverage the transferability of the generated 
adversarial samples to poison the target system. We also use the 
influence function to efficiently estimate the influence of injected 
samples on recommendation results, without re-training the models. 
Extensive experiments on multiple datasets against four representative 
recommendation models show that the proposed LOKI outperformances 
existing method. We also discuss the characteristics of vulnerable 
users/items, and evaluate whether anomaly detection methods can be used 
to mitigate the impact of data poisoning attacks.</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2022</td>
					</tr>
					<tr>
					<th>短标题</th>
						<td>LOKI</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>IEEE Xplore</td>
					</tr>
					<tr>
					<th>其它</th>
						<td>Conference Name: IEEE Transactions on Knowledge and Data Engineering</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>1-13</td>
					</tr>
					<tr>
					<th>期刊</th>
						<td>IEEE Transactions on Knowledge and Data Engineering</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/TKDE.2022.3181270">10.1109/TKDE.2022.3181270</a></td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>1558-2191</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午8:05:50</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午8:33:14</td>
					</tr>
				</tbody></table>
				<h3 class="tags">标签：</h3>
				<ul class="tags">
					<li>Adversarial Learning</li>
					<li>Behavioral sciences</li>
					<li>Collaborative filtering</li>
					<li>Data Poisoning</li>
					<li>Detectors</li>
					<li>Recommendation System</li>
					<li>Recurrent neural networks</li>
					<li>Reinforcement learning</li>
					<li>Task analysis</li>
					<li>Training</li>
				</ul>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_JHNVZ977">IEEE Xplore Abstract Record					</li>
					<li id="item_X4ZCGSFE">IEEE Xplore Full Text PDF					</li>
				</ul>
			</li>


			<li id="item_YLHRMCA8" class="item webpage">
			<h2>LOKI: A Practical Data Poisoning Attack Framework against Next Item Recommendations | IEEE Journals &amp; Magazine | IEEE Xplore</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>网页</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://ieeexplore.ieee.org/abstract/document/9806383">https://ieeexplore.ieee.org/abstract/document/9806383</a></td>
					</tr>
					<tr>
					<th>访问时间</th>
						<td>2022/11/16 下午8:06:46</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午8:06:46</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午8:06:46</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_MILQDLRY">LOKI: A Practical Data Poisoning Attack 
Framework against Next Item Recommendations | IEEE Journals &amp; 
Magazine | IEEE Xplore					</li>
				</ul>
			</li>


			<li id="item_MAV8NQVT" class="item conferencePaper">
			<h2>Msap: Multi-step adversarial perturbations on recommender systems embeddings</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>会议论文</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Vito Walter Anelli</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Alejandro Bellogin</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Yashar Deldjoo</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Tommaso Di Noia</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Felice Antonio Merra</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2021</td>
					</tr>
					<tr>
					<th>短标题</th>
						<td>Msap</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Google Scholar</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>1–6</td>
					</tr>
					<tr>
					<th>会议论文集标题</th>
						<td>The 34th International FLAIRS Conference. The Florida AI Research Society (FLAIRS), AAAI Press</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午7:56:31</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午7:56:31</td>
					</tr>
				</tbody></table>
			</li>


			<li id="item_6ZPPYWB2" class="item conferencePaper">
			<h2>MSPLD: Shilling Attack Detection Model Based on Meta Self-Paced Learning</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>会议论文</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Yanjing Yang</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Min Gao</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Yuerang Li</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Fan Wu</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Jia Wang</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Quanwu Zhao</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2021</td>
					</tr>
					<tr>
					<th>短标题</th>
						<td>MSPLD</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Google Scholar</td>
					</tr>
					<tr>
					<th>出版社</th>
						<td>IEEE</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>1–8</td>
					</tr>
					<tr>
					<th>会议论文集标题</th>
						<td>2021 International Joint Conference on Neural Networks (IJCNN)</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午8:19:46</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/17 下午6:31:29</td>
					</tr>
				</tbody></table>
				<h3 class="tags">标签：</h3>
				<ul class="tags">
					<li>Feature extraction</li>
					<li>Training</li>
					<li>Adaptation models</li>
					<li>Analytical models</li>
					<li>meta self-paced learning</li>
					<li>Metadata</li>
					<li>Neural networks</li>
					<li>Reliability theory</li>
					<li>shilling attack detection</li>
					<li>visual theoretical reliability analysis</li>
				</ul>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_MUTCBTCY">IEEE Xplore Abstract Record					</li>
					<li id="item_HKJCVRMC">IEEE Xplore Full Text PDF					</li>
					<li id="item_39S9IGJJ">Snapshot					</li>
				</ul>
			</li>


			<li id="item_AQUWHXKG" class="item journalArticle">
			<h2>On the feasibility of crawling-based attacks against recommender systems 1</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>期刊文章</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Fabio Aiolli</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Mauro Conti</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Stjepan Picek</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Mirko Polato</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2022</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Google Scholar</td>
					</tr>
					<tr>
					<th>其它</th>
						<td>Publisher: IOS Press</td>
					</tr>
					<tr>
					<th>卷次</th>
						<td>30</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>599–621</td>
					</tr>
					<tr>
					<th>期刊</th>
						<td>Journal of Computer Security</td>
					</tr>
					<tr>
					<th>期号</th>
						<td>4</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午8:09:45</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午8:09:45</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_VHGVP3PI">Snapshot					</li>
				</ul>
			</li>


			<li id="item_UBNEYZGT" class="item journalArticle">
			<h2>PipAttack: Poisoning Federated Recommender Systems forManipulating Item Promotion</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>期刊文章</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Shijie Zhang</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Hongzhi Yin</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Tong Chen</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Zi Huang</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Quoc Viet Hung Nguyen</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Lizhen Cui</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2021</td>
					</tr>
					<tr>
					<th>短标题</th>
						<td>PipAttack</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Google Scholar</td>
					</tr>
					<tr>
					<th>期刊</th>
						<td>arXiv preprint arXiv:2110.10926</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午7:34:14</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午7:34:14</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_QWQZ67BZ">Full Text					</li>
					<li id="item_JZSCABML">Snapshot					</li>
				</ul>
			</li>


			<li id="item_ZNQVFJWA" class="item journalArticle">
			<h2>Poison A⬚⬚ acks against Graph Representation Learning in Recommender Systems</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>期刊文章</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Thanh Toan Nguyen</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Khang Nguyen Duc Quach</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Thanh Tam Nguyen</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Thanh Trung Huynh</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Viet Hung Vu</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Phi Le Nguyen</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Jun Jo</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Quoc Viet Hung Nguyen</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2022</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Google Scholar</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午7:56:31</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午7:56:31</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_PCYG93TZ">Full Text					</li>
				</ul>
			</li>


			<li id="item_QF75A6VY" class="item conferencePaper">
			<h2>Poisoning Attacks to Graph-Based Recommender Systems</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>会议论文</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Minghong Fang</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Guolei Yang</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Neil Zhenqiang Gong</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Jia Liu</td>
					</tr>
					<tr>
					<th>摘要</th>
						<td>Recommender system is an important component of many web 
services to help users locate items that match their interests. Several 
studies showed that recommender systems are vulnerable to poisoning 
attacks, in which an attacker injects fake data to a recommender system 
such that the system makes recommendations as the attacker desires. 
However, these poisoning attacks are either agnostic to recommendation 
algorithms or optimized to recommender systems (e.g., 
association-rule-based or matrix-factorization-based recommender 
systems) that are not graph-based. Like association-rule-based and 
matrix-factorization-based recommender systems, graph-based recommender 
system is also deployed in practice, e.g., eBay, Huawei App Store (a big
 app store in China). However, how to design optimized poisoning attacks
 for graph-based recommender systems is still an open problem. In this 
work, we perform a systematic study on poisoning attacks to graph-based 
recommender systems. We consider an attacker's goal is to promote a 
target item to be recommended to as many users as possible. To achieve 
this goal, our a"acks inject fake users with carefully crafted rating 
scores to the recommender system. Due to limited resources and to avoid 
detection, we assume the number of fake users that can be injected into 
the system is bounded. The key challenge is how to assign rating scores 
to the fake users such that the target item is recommended to as many 
normal users as possible. To address the challenge, we formulate the 
poisoning attacks as an optimization problem, solving which determines 
the rating scores for the fake users. We also propose techniques to 
solve the optimization problem. We evaluate our attacks and compare them
 with existing attacks under white-box (recommendation algorithm and its
 parameters are known), gray-box (recommendation algorithm is known but 
its parameters are unknown), and blackbox (recommendation algorithm is 
unknown) settings using two real-world datasets. Our results show that 
our attack is effective and outperforms existing attacks for graph-based
 recommender systems. For instance, when 1% of users are injected fake 
users, our attack can make a target item recommended to 580 times more 
normal users in certain scenarios.</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>十二月 3, 2018</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>ACM Digital Library</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://doi.org/10.1145/3274694.3274706">https://doi.org/10.1145/3274694.3274706</a></td>
					</tr>
					<tr>
					<th>访问时间</th>
						<td>2022/11/16 上午8:00:00</td>
					</tr>
					<tr>
					<th>地点</th>
						<td>New York, NY, USA</td>
					</tr>
					<tr>
					<th>出版社</th>
						<td>Association for Computing Machinery</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-1-4503-6569-7</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>381–392</td>
					</tr>
					<tr>
					<th>系列</th>
						<td>ACSAC '18</td>
					</tr>
					<tr>
					<th>会议论文集标题</th>
						<td>Proceedings of the 34th Annual Computer Security Applications Conference</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1145/3274694.3274706">10.1145/3274694.3274706</a></td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/17 上午12:34:19</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/17 上午12:34:19</td>
					</tr>
				</tbody></table>
				<h3 class="tags">标签：</h3>
				<ul class="tags">
					<li>Adversarial recommender systems</li>
					<li>adversarial machine learning</li>
					<li>poisoning attacks</li>
				</ul>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_A25JI7PW">已提交版本					</li>
				</ul>
			</li>


			<li id="item_RLKPHKJZ" class="item journalArticle">
			<h2>Poisoning Deep Learning based Recommender Model in Federated Learning Scenarios</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>期刊文章</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Dazhong Rong</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Qinming He</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Jianhai Chen</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2022</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Google Scholar</td>
					</tr>
					<tr>
					<th>期刊</th>
						<td>arXiv preprint arXiv:2204.13594</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午7:54:32</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午7:54:32</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_KIFCB265">Full Text					</li>
					<li id="item_QMGFE66Y">Snapshot					</li>
				</ul>
			</li>


			<li id="item_SZEVEY7V" class="item journalArticle">
			<h2>Poisoning GNN-based Recommender Systems with Generative Surrogate-based Attacks</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>期刊文章</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Thanh Toan Nguyen</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Khang Nguyen Duc Quach</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Thanh Tam Nguyen</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Thanh Trung Huynh</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Viet Hung Vu</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Phi Le Nguyen</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Jun Jo</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Quoc Viet Hung Nguyen</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2022</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Google Scholar</td>
					</tr>
					<tr>
					<th>其它</th>
						<td>Publisher: ACM New York, NY</td>
					</tr>
					<tr>
					<th>期刊</th>
						<td>ACM Transactions on Information Systems</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午7:54:32</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午7:54:32</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_E5MWDDYM">Full Text					</li>
					<li id="item_Y55H7JMF">Snapshot					</li>
				</ul>
			</li>


			<li id="item_YLMBV7YC" class="item conferencePaper">
			<h2>Practical Data Poisoning Attack against Next-Item Recommendation</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>会议论文</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Hengtong Zhang</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Yaliang Li</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Bolin Ding</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Jing Gao</td>
					</tr>
					<tr>
					<th>摘要</th>
						<td>Online recommendation systems make use of a variety of 
information sources to provide users the items that users are 
potentially interested in. However, due to the openness of the online 
platform, recommendation systems are vulnerable to data poisoning 
attacks. Existing attack approaches are either based on simple heuristic
 rules or designed against specific recommendations approaches. The 
former often suffers unsatisfactory performance, while the latter 
requires strong knowledge of the target system. In this paper, we focus 
on a general next-item recommendation setting and propose a practical 
poisoning attack approach named LOKI against blackbox recommendation 
systems. The proposed LOKI utilizes the reinforcement learning algorithm
 to train the attack agent, which can be used to generate user behavior 
samples for data poisoning. In real-world recommendation systems, the 
cost of retraining recommendation models is high, and the interaction 
frequency between users and a recommendation system is restricted. Given
 these real-world restrictions, we propose to let the agent interact 
with a recommender simulator instead of the target recommendation system
 and leverage the transferability of the generated adversarial samples 
to poison the target system. We also propose to use the influence 
function to efficiently estimate the influence of injected samples on 
the recommendation results, without re-training the models within the 
simulator. Extensive experiments on two datasets against four 
representative recommendation models show that the proposed LOKI 
achieves better attacking performance than existing methods.</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2020-04-20</td>
					</tr>
					<tr>
					<th>语言</th>
						<td>en</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://dl.acm.org/doi/10.1145/3366423.3379992">https://dl.acm.org/doi/10.1145/3366423.3379992</a></td>
					</tr>
					<tr>
					<th>访问时间</th>
						<td>2022/11/16 下午6:39:51</td>
					</tr>
					<tr>
					<th>地点</th>
						<td>Taipei Taiwan</td>
					</tr>
					<tr>
					<th>出版社</th>
						<td>ACM</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-1-4503-7023-3</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>2458-2464</td>
					</tr>
					<tr>
					<th>会议论文集标题</th>
						<td>Proceedings of The Web Conference 2020</td>
					</tr>
					<tr>
					<th>会议名称</th>
						<td>WWW '20: The Web Conference 2020</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1145/3366423.3379992">10.1145/3366423.3379992</a></td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午6:39:51</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午8:33:08</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_K8QY7YS8">Zhang 等 - 2020 - Practical Data Poisoning Attack against Next-Item .pdf					</li>
				</ul>
			</li>


			<li id="item_GXNWB2FR" class="item conferencePaper">
			<h2>Rank List Sensitivity of Recommender Systems to Interaction Perturbations</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>会议论文</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Sejoon Oh</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Berk Ustun</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Julian McAuley</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Srijan Kumar</td>
					</tr>
					<tr>
					<th>摘要</th>
						<td>Prediction models can exhibit sensitivity with respect to 
training data: small changes in the training data can produce models 
that assign conflicting predictions to individual data points during 
test time. In this work, we study this sensitivity in recommender 
systems, where users' recommendations are drastically altered by minor 
perturbations in other unrelated users' interactions. We introduce a 
measure of stability for recommender systems, called Rank List 
Sensitivity (RLS), which measures how rank lists generated by a given 
recommender system at test time change as a result of a perturbation in 
the training data. We develop a method, CASPER, which uses cascading 
effect to identify the minimal and systematical perturbation to induce 
higher instability in a recommender system. Experiments on four datasets
 show that recommender models are overly sensitive to minor 
perturbations introduced randomly or via CASPER - even perturbing one 
random interaction of one user drastically changes the recommendation 
lists of all users.Importantly, with CASPER perturbation, the models 
generate more unstable recommend ations for low-accuracy users (i.e., 
those who receive low-quality recommendations) than high-accuracy ones.</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>十月 17, 2022</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>ACM Digital Library</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://doi.org/10.1145/3511808.3557425">https://doi.org/10.1145/3511808.3557425</a></td>
					</tr>
					<tr>
					<th>访问时间</th>
						<td>2022/11/16 上午8:00:00</td>
					</tr>
					<tr>
					<th>地点</th>
						<td>New York, NY, USA</td>
					</tr>
					<tr>
					<th>出版社</th>
						<td>Association for Computing Machinery</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-1-4503-9236-5</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>1584–1594</td>
					</tr>
					<tr>
					<th>系列</th>
						<td>CIKM '22</td>
					</tr>
					<tr>
					<th>会议论文集标题</th>
						<td>Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1145/3511808.3557425">10.1145/3511808.3557425</a></td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/17 上午12:31:52</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/17 上午12:31:52</td>
					</tr>
				</tbody></table>
				<h3 class="tags">标签：</h3>
				<ul class="tags">
					<li>recommender systems</li>
					<li>input data perturbation</li>
					<li>model stability</li>
				</ul>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_6N6JXYD9">Full Text PDF					</li>
				</ul>
			</li>


			<li id="item_BFV7H48K" class="item journalArticle">
			<h2>Rating behavior evaluation and abnormality forensics analysis for injection attack detection</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>期刊文章</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Zhihai Yang</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Qindong Sun</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Zhaoli Liu</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Jinpei Yan</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Yaling Zhang</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2022</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Google Scholar</td>
					</tr>
					<tr>
					<th>其它</th>
						<td>Publisher: Springer</td>
					</tr>
					<tr>
					<th>卷次</th>
						<td>59</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>93–119</td>
					</tr>
					<tr>
					<th>期刊</th>
						<td>Journal of Intelligent Information Systems</td>
					</tr>
					<tr>
					<th>期号</th>
						<td>1</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午7:58:52</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午7:58:52</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_JB3HJ8TV">Snapshot					</li>
				</ul>
			</li>


			<li id="item_N7RR8L9S" class="item journalArticle">
			<h2>Ready for emerging threats to recommender systems? A graph convolution-based generative shilling attack</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>期刊文章</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Fan Wu</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Min Gao</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Junliang Yu</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Zongwei Wang</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Kecheng Liu</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Xu Wang</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2021</td>
					</tr>
					<tr>
					<th>短标题</th>
						<td>Ready for emerging threats to recommender systems?</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Google Scholar</td>
					</tr>
					<tr>
					<th>其它</th>
						<td>Publisher: Elsevier</td>
					</tr>
					<tr>
					<th>卷次</th>
						<td>578</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>683–701</td>
					</tr>
					<tr>
					<th>期刊</th>
						<td>Information Sciences</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午7:28:34</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午7:28:34</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_7QRU6H55">Full Text					</li>
					<li id="item_ZZRYEPZD">Snapshot					</li>
				</ul>
			</li>


			<li id="item_FEK74DXC" class="item conferencePaper">
			<h2>Reverse Attack: Black-box Attacks on Collaborative Recommendation</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>会议论文</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Yihe Zhang</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Xu Yuan</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Jin Li</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Jiadong Lou</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Li Chen</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Nian-Feng Tzeng</td>
					</tr>
					<tr>
					<th>摘要</th>
						<td>Collaborative filtering (CF) recommender systems have been 
extensively developed and widely deployed in various social websites, 
promoting products or services to the users of interest. Meanwhile, work
 has been attempted at poisoning attacks to CF recommender systems for 
distorting the recommend results to reap commercial or personal gains 
stealthily. While existing poisoning attacks have demonstrated their 
effectiveness with the offline social datasets, they are impractical 
when applied to the real setting on online social websites. This paper 
develops a novel and practical poisoning attack solution toward the CF 
recommender systems without knowing involved specific algorithms nor 
historical social data information a priori. Instead of directly 
attacking the unknown recommender systems, our solution performs certain
 operations on the social websites to collect a set of sampling data for
 use in constructing a surrogate model for deeply learning the inherent 
recommendation patterns. This surrogate model can estimate the item 
proximities, learned by the recommender systems. By attacking the 
surrogate model, the corresponding solutions (for availability and 
target attacks) can be directly migrated to attack the original 
recommender systems. Extensive experiments validate the generated 
surrogate model's reproductive capability and demonstrate the 
effectiveness of our attack upon various CF recommender algorithms.</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>十一月 13, 2021</td>
					</tr>
					<tr>
					<th>短标题</th>
						<td>Reverse Attack</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>ACM Digital Library</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://doi.org/10.1145/3460120.3484805">https://doi.org/10.1145/3460120.3484805</a></td>
					</tr>
					<tr>
					<th>访问时间</th>
						<td>2022/11/16 上午8:00:00</td>
					</tr>
					<tr>
					<th>地点</th>
						<td>New York, NY, USA</td>
					</tr>
					<tr>
					<th>出版社</th>
						<td>Association for Computing Machinery</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-1-4503-8454-4</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>51–68</td>
					</tr>
					<tr>
					<th>系列</th>
						<td>CCS '21</td>
					</tr>
					<tr>
					<th>会议论文集标题</th>
						<td>Proceedings of the 2021 ACM SIGSAC Conference on Computer and Communications Security</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1145/3460120.3484805">10.1145/3460120.3484805</a></td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/17 上午12:29:50</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/17 上午12:29:50</td>
					</tr>
				</tbody></table>
				<h3 class="tags">标签：</h3>
				<ul class="tags">
					<li>poisoning attack</li>
					<li>recommender system</li>
				</ul>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_PNI7XCDS">Full Text PDF					</li>
				</ul>
			</li>


			<li id="item_25IEA25E" class="item journalArticle">
			<h2>Revisiting Injective Attacks on Recommender Systems</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>期刊文章</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Haoyang Li</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Shimin Di</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Lei Chen</td>
					</tr>
					<tr>
					<th>摘要</th>
						<td>Recent studies have demonstrated that recommender systems 
(RecSys) are vulnerable to injective attacks. Given a limited fake user 
budget, attackers can inject fake users with carefully designed 
behaviors into the open platforms, making RecSys recommend a target item
 to more real users for proﬁts. In this paper, we ﬁrst revisit existing 
attackers and reveal that they suffer from the difﬁculty-agnostic and 
diversity-deﬁcit issues. Existing attackers concentrate their efforts on
 difﬁcult users who have low tendencies toward the target item, thus 
reducing their effectiveness. Moreover, they are incapable of affecting 
the target RecSys to recommend the target item to real users in a 
diverse manner, because their generated fake user behaviors are 
dominated by large communities. To alleviate these two issues, we 
propose a difﬁculty and diversity aware attacker, namely DADA. We design
 the difﬁculty-aware and diversity-aware objectives to enable easy users
 from various communities to contribute more weights when optimizing 
attackers. By incorporating these two objectives, the proposed attacker 
DADA can concentrate on easy users while also affecting a broader range 
of real users simultaneously, thereby boosting the effectiveness. 
Extensive experiments on three real-world datasets demonstrate the 
effectiveness of our proposed attacker.</td>
					</tr>
					<tr>
					<th>语言</th>
						<td>en</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Zotero</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>14</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午8:05:32</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午8:05:33</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_KNHJA5VC">Li 等 - Revisiting Injective Attacks on Recommender System.pdf					</li>
				</ul>
			</li>


			<li id="item_BCXEL8ET" class="item journalArticle">
			<h2>Revisiting Item Promotion in GNN-based Collaborative Filtering: A Masked Targeted Topological Attack Perspective</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>期刊文章</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Yongwei Wang</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Yong Liu</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Zhiqi Shen</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2022</td>
					</tr>
					<tr>
					<th>短标题</th>
						<td>Revisiting Item Promotion in GNN-based Collaborative Filtering</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Google Scholar</td>
					</tr>
					<tr>
					<th>期刊</th>
						<td>arXiv preprint arXiv:2208.09979</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午8:19:46</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午8:19:46</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_T4JWTDBN">Full Text					</li>
					<li id="item_NYMV5A9Z">Snapshot					</li>
				</ul>
			</li>


			<li id="item_AC5UBIU3" class="item conferencePaper">
			<h2>RGRecSys: A Toolkit for Robustness Evaluation of Recommender Systems</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>会议论文</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Zohreh Ovaisi</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Shelby Heinecke</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Jia Li</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Yongfeng Zhang</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Elena Zheleva</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Caiming Xiong</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2022</td>
					</tr>
					<tr>
					<th>短标题</th>
						<td>RGRecSys</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Google Scholar</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>1597–1600</td>
					</tr>
					<tr>
					<th>会议论文集标题</th>
						<td>Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午7:54:32</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午7:54:32</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_MCME8827">Full Text					</li>
					<li id="item_GY5DL3WG">Snapshot					</li>
				</ul>
			</li>


			<li id="item_Y4TRTDFS" class="item journalArticle">
			<h2>RMPD: Method for enhancing the robustness of recommendations with attack environments</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>期刊文章</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Qi Ding</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Peiyu Liu</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Zhenfang Zhu</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Huajuan Duan</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Fuyong Xu</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2021</td>
					</tr>
					<tr>
					<th>短标题</th>
						<td>RMPD</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Google Scholar</td>
					</tr>
					<tr>
					<th>其它</th>
						<td>Publisher: IEEE</td>
					</tr>
					<tr>
					<th>卷次</th>
						<td>9</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>17843–17853</td>
					</tr>
					<tr>
					<th>期刊</th>
						<td>IEEE Access</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午7:34:14</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午7:34:14</td>
					</tr>
				</tbody></table>
			</li>


			<li id="item_H9ANMSYK" class="item journalArticle">
			<h2>SARCP: Exploiting Cyber-Attack Prediction Through Socially-Aware Recommendation</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>期刊文章</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Nana Yaw Asabere</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Elikem Fiamavle</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Joseph Agyiri</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Wisdom Kwawu Torgby</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Joseph Eyram Dzata</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Nina Pearl Doe</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2022</td>
					</tr>
					<tr>
					<th>短标题</th>
						<td>SARCP</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Google Scholar</td>
					</tr>
					<tr>
					<th>其它</th>
						<td>Publisher: IGI Global</td>
					</tr>
					<tr>
					<th>卷次</th>
						<td>14</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>1–21</td>
					</tr>
					<tr>
					<th>期刊</th>
						<td>International Journal of Decision Support System Technology (IJDSST)</td>
					</tr>
					<tr>
					<th>期号</th>
						<td>1</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午7:58:52</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午7:58:52</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_N32SEJGX">Snapshot					</li>
				</ul>
			</li>


			<li id="item_3UG8YWRP" class="item journalArticle">
			<h2>Semi-supervised recommendation attack detection based on Co-Forest</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>期刊文章</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Quanqiang Zhou</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Liangliang Duan</td>
					</tr>
					<tr>
					<th>摘要</th>
						<td>In recommendation attack, malicious users attempt to bias the 
recommendation results by injecting fake profiles into the rating 
database. To detect such attack, three types of methods, i.e., 
unsupervised, supervised and semi-supervised, have been proposed. Among 
these works, the advantage of semi-supervised methods is that they can 
use the unlabeled user profiles to improve the detection performance. 
However, the existing semi-supervised methods suffer from low precision.
 Aiming at this problem, in this paper, we propose a semi-supervised 
detection approach named SSADR-CoF based on the Co-Forest algorithm. 
Being different from the existing semi-supervised methods which only use
 a few of features to train a single classifier for the detection, the 
proposed approach uses a series of features to train an ensemble of 
classifiers to detect the recommendation attack. We first use the window
 dividing and rating behavior statistical methods to extract a series of
 user rating behavior mode features for training the detection model. 
Then, we use a small number of labeled user profiles to initialize an 
ensemble of classifiers, and use the ensemble of classifiers to assign 
labels to the unlabeled user profiles. Finally, we use the labeled and 
the newly labeled user profiles to iteratively update the classifiers 
for the detection. Experiments conducted on three benchmark datasets 
MovieLens 10M, MovieLens 25M, and Amazon show that the proposed approach
 can effectively improve the precision of the semi-supervised methods 
under the condition of maintaining high recall and AUC.</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2021-10-01</td>
					</tr>
					<tr>
					<th>语言</th>
						<td>en</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>ScienceDirect</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://www.sciencedirect.com/science/article/pii/S0167404821002145">https://www.sciencedirect.com/science/article/pii/S0167404821002145</a></td>
					</tr>
					<tr>
					<th>访问时间</th>
						<td>2022/11/16 下午8:13:01</td>
					</tr>
					<tr>
					<th>卷次</th>
						<td>109</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>102390</td>
					</tr>
					<tr>
					<th>期刊</th>
						<td>Computers &amp; Security</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1016/j.cose.2021.102390">10.1016/j.cose.2021.102390</a></td>
					</tr>
					<tr>
					<th>刊名缩写</th>
						<td>Computers &amp; Security</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>0167-4048</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午8:13:01</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午8:13:01</td>
					</tr>
				</tbody></table>
				<h3 class="tags">标签：</h3>
				<ul class="tags">
					<li>Attack detection</li>
					<li>Co-Forest algorithm</li>
					<li>Collaborative recommender system</li>
					<li>Recommendation attack</li>
					<li>Semi-supervised learning</li>
				</ul>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_HHBBAB8S">ScienceDirect Full Text PDF					</li>
				</ul>
			</li>


			<li id="item_8CAXGBEI" class="item journalArticle">
			<h2>Sequential Attack Detection in Recommender Systems</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>期刊文章</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Mehmet Aktukmak</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Yasin Yilmaz</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Ismail Uysal</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2021</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Google Scholar</td>
					</tr>
					<tr>
					<th>其它</th>
						<td>Publisher: IEEE</td>
					</tr>
					<tr>
					<th>卷次</th>
						<td>16</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>3285–3298</td>
					</tr>
					<tr>
					<th>期刊</th>
						<td>IEEE Transactions on Information Forensics and Security</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午7:28:34</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/17 下午6:31:31</td>
					</tr>
				</tbody></table>
				<h3 class="tags">标签：</h3>
				<ul class="tags">
					<li>Computational modeling</li>
					<li>Recommender systems</li>
					<li>Data models</li>
					<li>cyber-attack detection</li>
					<li>Data integration</li>
					<li>Detection algorithms</li>
					<li>Hidden Markov models</li>
					<li>History</li>
					<li>latent variable model</li>
					<li>quickest detection</li>
					<li>variational inference</li>
				</ul>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_KPGF3TWJ">IEEE Xplore Full Text PDF					</li>
					<li id="item_8MAWN9Q8">Snapshot					</li>
				</ul>
			</li>


			<li id="item_CTHSWK5Y" class="item conferencePaper">
			<h2>Shilling Attack Detection System for Online Recommenders</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>会议论文</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>J. R. V. Jeny</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>R. Sowmya</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>G. Sai Kiran</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>M. Kiran Babu</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Ch Arjun</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2022</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Google Scholar</td>
					</tr>
					<tr>
					<th>出版社</th>
						<td>IEEE</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>988–992</td>
					</tr>
					<tr>
					<th>会议论文集标题</th>
						<td>2022 International Conference on Inventive Computation Technologies (ICICT)</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午8:19:46</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/17 下午6:31:33</td>
					</tr>
				</tbody></table>
				<h3 class="tags">标签：</h3>
				<ul class="tags">
					<li>Clustering algorithms</li>
					<li>Recommender systems</li>
					<li>Computational efficiency</li>
					<li>DBSCAN clustering algorithm</li>
					<li>Detecting Group Shilling attacks</li>
					<li>Group Shilling attacks</li>
					<li>Online recommendation system</li>
					<li>Recommender System</li>
				</ul>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_NAKCWZDM">IEEE Xplore Full Text PDF					</li>
					<li id="item_EADN62KP">Snapshot					</li>
				</ul>
			</li>


			<li id="item_WZRIABCY" class="item preprint">
			<h2>Targeted Data Poisoning Attack on News Recommendation System by Content Perturbation</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>预印本</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Xudong Zhang</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Zan Wang</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Jingke Zhao</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Lanjun Wang</td>
					</tr>
					<tr>
					<th>摘要</th>
						<td>News Recommendation System(NRS) has become a fundamental 
technology to many online news services. Meanwhile, several studies show
 that recommendation systems(RS) are vulnerable to data poisoning 
attacks, and the attackers have the ability to mislead the system to 
perform as their desires. A widely studied attack approach, injecting 
fake users, can be applied on the NRS when the NRS is treated the same 
as the other systems whose items are fixed. However, in the NRS, as each
 item (i.e. news) is more informative, we propose a novel approach to 
poison the NRS, which is to perturb contents of some browsed news that 
results in the manipulation of the rank of the target news. Intuitively,
 an attack is useless if it is highly likely to be caught, i.e., 
exposed. To address this, we introduce a notion of the exposure risk and
 propose a novel problem of attacking a history news dataset by means of
 perturbations where the goal is to maximize the manipulation of the 
target news rank while keeping the risk of exposure under a given 
budget. We design a reinforcement learning framework, called TDP-CP, 
which contains a two-stage hierarchical model to reduce the searching 
space. Meanwhile, influence estimation is also applied to save the time 
on retraining the NRS for rewards. We test the performance of TDP-CP 
under three NRSs and on different target news. Our experiments show that
 TDP-CP can increase the rank of the target news successfully with a 
limited exposure budget.</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2022-03-09</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>arXiv.org</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://arxiv.org/abs/2203.03560">http://arxiv.org/abs/2203.03560</a></td>
					</tr>
					<tr>
					<th>访问时间</th>
						<td>2022/11/17 上午12:25:55</td>
					</tr>
					<tr>
					<th>其它</th>
						<td>arXiv:2203.03560 [cs]</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.48550/arXiv.2203.03560">10.48550/arXiv.2203.03560</a></td>
					</tr>
					<tr>
					<th>仓库</th>
						<td>arXiv</td>
					</tr>
					<tr>
					<th>存档ID</th>
						<td>arXiv:2203.03560</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/17 上午12:25:55</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/17 上午12:25:55</td>
					</tr>
				</tbody></table>
				<h3 class="tags">标签：</h3>
				<ul class="tags">
					<li>Computer Science - Cryptography and Security</li>
					<li>Computer Science - Information Retrieval</li>
					<li>Computer Science - Machine Learning</li>
					<li>Computer Science - Artificial Intelligence</li>
				</ul>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_P3SEE9LJ">arXiv Fulltext PDF					</li>
					<li id="item_7NSHFP28">arXiv.org Snapshot					</li>
				</ul>
			</li>


			<li id="item_PDGTKDWY" class="item journalArticle">
			<h2>Three Birds With One Stone: User Intention Understanding and Influential Neighbor Disclosure for Injection Attack Detection</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>期刊文章</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Zhihai Yang</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Qindong Sun</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Zhaoli Liu</td>
					</tr>
					<tr>
					<th>摘要</th>
						<td>Recommender system, as a data-driven way to help customers 
locate products that match their interests, is increasingly critical for
 providing competitive customer suggestions in many web services. 
However, recommender systems are highly vulnerable to malicious 
injection attacks due to their fundamental vulnerabilities and openness.
 With the endless emergence of new attacks, how to provide a feasible 
way for defending different malicious threats against online 
recommendations is still an under-explored issue. In this paper, we 
explore a new way to defend malicious injection attacks through user 
intention understanding and influential neighbour disclosure. 
Specifically, we propose a detection approach, termed TBOS (Three Birds 
with One Stone), to deal with different malicious threats. In TBOS, we 
first develop the discrimination of attack target by combining global 
influence evaluation and risk attitude estimation of users. In order to 
make TBOS controllable, second, we propose to incorporate an optimal 
denoising mechanism to remove disturbed information before detection. To
 enhance the representativeness and predictability of detection model, 
finally, we propose to leverage a behavioral label propagation mechanism
 based on constructed label space for the determination of malicious 
injection behaviors. Extensive experiments on both synthetic and real 
data demonstrate that TBOS outperforms all baselines in different cases.
 Particularly, the detection performance of TBOS can achieve an 
improvement of 6.08% FAR (false alarm rate) for optimal-injection 
attacks, an improvement of 3.83% FAR in average for co-visitation 
injection attacks, as well as an improvement of 2.3% for profile 
injection attacks over benchmarks in terms of FAR while keeping the 
highest DR (detection rate). Additional experiments on real-world data 
show that TBOS brings an improvement with the advantage of 6.5% FAR in 
average compared with baselines.</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2022</td>
					</tr>
					<tr>
					<th>短标题</th>
						<td>Three Birds With One Stone</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>IEEE Xplore</td>
					</tr>
					<tr>
					<th>其它</th>
						<td>Conference Name: IEEE Transactions on Information Forensics and Security</td>
					</tr>
					<tr>
					<th>卷次</th>
						<td>17</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>531-546</td>
					</tr>
					<tr>
					<th>期刊</th>
						<td>IEEE Transactions on Information Forensics and Security</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/TIFS.2022.3146769">10.1109/TIFS.2022.3146769</a></td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>1556-6021</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午8:13:39</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午8:13:39</td>
					</tr>
				</tbody></table>
				<h3 class="tags">标签：</h3>
				<ul class="tags">
					<li>Recommender systems</li>
					<li>Predictive models</li>
					<li>attack detection</li>
					<li>behavior representation</li>
					<li>Birds</li>
					<li>Estimation</li>
					<li>Injection attack</li>
					<li>performance analysis</li>
					<li>Position measurement</li>
					<li>Sun</li>
					<li>Technological innovation</li>
				</ul>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_ZA4MLQKN">IEEE Xplore Abstract Record					</li>
					<li id="item_P5AT2SMN">IEEE Xplore Full Text PDF					</li>
				</ul>
			</li>


			<li id="item_EDFVDSDX" class="item journalArticle">
			<h2>Towards Adversarially Superior Malware Detection Models: An 
Adversary Aware Proactive Approach using Adversarial Attacks and 
Defenses</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>期刊文章</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Hemant Rathore</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Adithya Samavedhi</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Sanjay K. Sahay</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Mohit Sewak</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2022</td>
					</tr>
					<tr>
					<th>短标题</th>
						<td>Towards Adversarially Superior Malware Detection Models</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Google Scholar</td>
					</tr>
					<tr>
					<th>其它</th>
						<td>Publisher: Springer</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>1–21</td>
					</tr>
					<tr>
					<th>期刊</th>
						<td>Information Systems Frontiers</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/16 下午6:49:21</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/16 下午6:49:21</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_DLE8T4DE">Snapshot					</li>
				</ul>
			</li>


			<li id="item_VMCZYDHX" class="item conferencePaper">
			<h2>Triple Adversarial Learning for Influence based Poisoning Attack in Recommender Systems</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>会议论文</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Chenwang Wu</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Defu Lian</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Yong Ge</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Zhihao Zhu</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Enhong Chen</td>
					</tr>
					<tr>
					<th>摘要</th>
						<td>As an important means to solve information overload, 
recommender systems have been widely applied in many fields, such as 
e-commerce and advertising. However, recent studies have shown that 
recommender systems are vulnerable to poisoning attacks; that is, 
injecting a group of carefully designed user profiles into the 
recommender system can severely affect recommendation quality. Despite 
the development from shilling attacks to optimization-based attacks, the
 imperceptibility and harmfulness of the generated data in most attacks 
are arduous to balance. To this end, we propose a triple adversarial 
learning for influence based poisoning attack (TrialAttack), a flexible 
end-to-end poisoning framework to generate non-notable and harmful user 
profiles. Specifically, given the input noise, TrialAttack directly 
generates malicious users through triple adversarial learning of the 
generator, discriminator, and influence module. Besides, to provide 
reliable influence for TrialAttack training, we explore a new 
approximation approach for estimating each fake user's influence. 
Through theoretical analysis, we prove that the distribution 
characterized by TrialAttack approximates to the rating distribution of 
real users under the premise of performing an efficient attack. This 
property allows the injected users to attack in an unremarkable way. 
Experiments on three real-world datasets show that TrialAttack's attack 
performance outperforms state-of-the-art attacks, and the generated fake
 profiles are more difficult to detect compared to baselines.</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>八月 14, 2021</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>ACM Digital Library</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://doi.org/10.1145/3447548.3467335">https://doi.org/10.1145/3447548.3467335</a></td>
					</tr>
					<tr>
					<th>访问时间</th>
						<td>2022/11/16 上午8:00:00</td>
					</tr>
					<tr>
					<th>地点</th>
						<td>New York, NY, USA</td>
					</tr>
					<tr>
					<th>出版社</th>
						<td>Association for Computing Machinery</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-1-4503-8332-5</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>1830–1840</td>
					</tr>
					<tr>
					<th>系列</th>
						<td>KDD '21</td>
					</tr>
					<tr>
					<th>会议论文集标题</th>
						<td>Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1145/3447548.3467335">10.1145/3447548.3467335</a></td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/17 上午12:31:32</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/17 下午6:31:34</td>
					</tr>
				</tbody></table>
				<h3 class="tags">标签：</h3>
				<ul class="tags">
					<li>recommender systems</li>
					<li>poisoning attacks</li>
					<li>adversarial learning</li>
				</ul>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_DUBYQBG7">Wu 等 - 2021 - Triple Adversarial Learning for Influence based Po.pdf					</li>
				</ul>
			</li>


			<li id="item_H6Q5F5XN" class="item journalArticle">
			<h2>UA-FedRec: Untargeted Attack on Federated News Recommendation</h2>
				<table>
					<tbody><tr>
						<th>类型</th>
						<td>期刊文章</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Jingwei Yi</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Fangzhao Wu</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Bin Zhu</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Yang Yu</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Chao Zhang</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Guangzhong Sun</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Xing Xie</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2022</td>
					</tr>
					<tr>
					<th>短标题</th>
						<td>UA-FedRec</td>
					</tr>
					<tr>
					<th>馆藏目录</th>
						<td>Google Scholar</td>
					</tr>
					<tr>
					<th>期刊</th>
						<td>arXiv preprint arXiv:2202.06701</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2022/11/17 上午12:32:11</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2022/11/17 上午12:32:11</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_TSIW76QA">Full Text					</li>
					<li id="item_FURW9FCA">Snapshot					</li>
				</ul>
			</li>

		</ul>
	
</body></html>